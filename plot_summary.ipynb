{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read summary file of simulations and plot results   \n",
    "\n",
    "After all simulations (`SIXTE`+ `xifusim`) a file is saved with all the information.   \n",
    "This notebook reads that file and plot\n",
    "1. **Histogram** of fraction of lost photons: has a 'normal' distribution? Can I assign a median value and a std deviation for that flux?   \n",
    "   It is important to establish a simulation time that produces enough number of close pairs that could give rise to pile-up. Here we check that the fractions obtained in the different simulations are 'normally' distributed so that we can finally obtain a mean value   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules for ploting and data manipulation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.visualization import hist\n",
    "import glob\n",
    "from scipy.stats import anderson, shapiro\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV files for all fluxes and store full information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csv files in current dir\n",
    "files = glob.glob('info*.csv')\n",
    "nfiles = len(files)\n",
    "# get list of fluxes from the files\n",
    "fluxes = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    fluxes.append(df['flux[mcrab]'].values[0])\n",
    "# sort the files by flux\n",
    "files = [x for _, x in sorted(zip(fluxes, files))]\n",
    "\n",
    "\n",
    "# open figure (mosaic with nfiles subplots)\n",
    "fig, axs = plt.subplots(3,3, figsize=(20,20))\n",
    "ax = axs.flatten()\n",
    "# loop over files\n",
    "for i in range(nfiles):\n",
    "    file = files[i]\n",
    "    # read data from csv file\n",
    "    df = pd.read_csv(file)\n",
    "    # Read columns \"simulation\" and \"fraction[%lost]\" for the given exposure time\n",
    "    sim = df[\"simulation\"]\n",
    "    frac = df[\"fraction_lost[%]\"]\n",
    "    # get data from the table\n",
    "    exposure = df['exposure[s]'].values[0]\n",
    "    filter = df['filter'].values[0]\n",
    "    focus = df['focus'].values[0]\n",
    "    Nimpacts = int(np.mean(df['Nimpacts'].values))\n",
    "    Nmissing = int(np.mean(df['Missing'].values))\n",
    "    flux_mcrab = df['flux[mcrab]'].values[0]\n",
    "    nsims = len(sim)\n",
    "    \n",
    "    # plot a histogram (in the corresponding axis) of the fraction of lost photons for each simulation \n",
    "    hist(frac, ax=ax[i],bins='scott', color=\"blue\", alpha=0.7)\n",
    "    ax[i].set_xlabel(\"Fraction of lost photons [%]\")\n",
    "    ax[i].set_ylabel(\"Number of simulations\")\n",
    "    #ax[i].set_title(f\"Histogram of fraction of lost photons ({len(sim)} simulations)\")\n",
    "    # print info about flux, exposure time, Nimpacts, filter and focus\n",
    "    mean = np.mean(frac)\n",
    "    std = np.std(frac)\n",
    "    pm_str = u\"\\u00B1\"\n",
    "\n",
    "    # do a normality test\n",
    "    stat, p = shapiro(frac)\n",
    "    #print(\"Shapiro-Wilk test statistic: \", stat)\n",
    "    #print(\"Shapiro-Wilk test p-value: \", p)\n",
    "    # print a conclusion about the normality of the data\n",
    "    if not p > 0.05:\n",
    "        print(f\"For flux {flux_mcrab}: The fraction of lost photons is NOT normally distributed (shapiro test)\")\n",
    "    \n",
    "    # do an anderson-darling test for normality\n",
    "    result = anderson(frac)\n",
    "    #print(\"Anderson-Darling test statistic: \", result.statistic)\n",
    "    #print(\"Anderson-Darling test critical values: \", result.critical_values)\n",
    "    #print(\"Anderson-Darling test significance levels: \", result.significance_level)\n",
    "    #print(\"Anderson-Darling test p-value: \", result.significance_level[2])\n",
    "    # print a conclusion about normality\n",
    "    normality = True\n",
    "    if not result.statistic < result.critical_values[2]:\n",
    "        print(f\"For {flux_mcrab}: The fraction of lost photons is NOT normally distributed (anderson test)\")\n",
    "        normality = False\n",
    "    boxtext = (f\"Flux: {flux_mcrab}mCrab\\nExposure time: {exposure} s\\n\"\n",
    "               f\"sims: {nsims}\\n<Nimpacts>: {Nimpacts}\\n\"\n",
    "               f\"<Nmissing>: {Nmissing}\\nFilter: {filter}\\n\"\n",
    "               f\"Focus: {focus}\\nMean: {mean:.3f} {pm_str} {std:.3f}%\\n\"\n",
    "               f\"Anderson-Darling normality: {normality}\\n\")\n",
    "    ax[i].text(0.45, 0.55, boxtext, fontsize=10, transform=ax[i].transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the figure to PNG file\n",
    "fig.savefig(\"Figures/normality/histograms_normality.png\", dpi=300)\n",
    "# save the figure to PDF file\n",
    "fig.savefig(\"Figures/normality/histograms_normality.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSFCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
