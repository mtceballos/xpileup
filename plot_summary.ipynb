{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read summary file of simulations and plot results   \n",
    "\n",
    "After all simulations (`SIXTE`+ `xifusim`) a file is saved with all the information.   \n",
    "This notebook reads that file and plot\n",
    "1. **Histogram** of fraction of lost photons: has a 'normal' distribution? Can I assign a median value and a std deviation for that flux?   \n",
    "   It is important to establish a simulation time that produces enough number of close pairs that could give rise to pile-up. Here we check that the fractions obtained in the different simulations are 'normally' distributed so that we can finally obtain a mean value   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules for ploting and data manipulation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.visualization import hist\n",
    "import glob\n",
    "from scipy.stats import anderson, shapiro\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_version = \"v5_20250621\" #v3_20240917\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV files for all fluxes and store full information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csv files in current dir\n",
    "files = glob.glob(f'{config_version}/info*.csv')\n",
    "nfiles = len(files)\n",
    "# get list of fluxes from the files\n",
    "fluxes = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    fluxes.append(df['flux[mcrab]'].values[0])\n",
    "# sort the files by flux\n",
    "files = [x for _, x in sorted(zip(fluxes, files))]\n",
    "\n",
    "\n",
    "# open figure (mosaic with nfiles subplots)\n",
    "fig, axs = plt.subplots(3,3, figsize=(20,20))\n",
    "ax = axs.flatten()\n",
    "# loop over files\n",
    "for i in range(nfiles):\n",
    "    file = files[i]\n",
    "    # read data from csv file\n",
    "    df = pd.read_csv(file)\n",
    "    # Read columns \"simulation\" and \"fraction[%lost]\" for the given exposure time\n",
    "    sim = df[\"simulation\"]\n",
    "    frac = df[\"fraction_lost[%]\"]\n",
    "    # get data from the table\n",
    "    exposure = df['exposure[s]'].values[0]\n",
    "    filter = df['filter'].values[0]\n",
    "    focus = df['focus'].values[0]\n",
    "    Nimpacts = int(np.mean(df['Nimpacts'].values))\n",
    "    Nmissing = int(np.mean(df['Missing'].values))\n",
    "    flux_mcrab = df['flux[mcrab]'].values[0]\n",
    "    nsims = len(sim)\n",
    "    \n",
    "    # plot a histogram (in the corresponding axis) of the fraction of lost photons for each simulation \n",
    "    hist(frac, ax=ax[i],bins='scott', color=\"blue\", alpha=0.7)\n",
    "    ax[i].set_xlabel(\"Fraction of lost photons [%]\")\n",
    "    ax[i].set_ylabel(\"Number of simulations\")\n",
    "    #ax[i].set_title(f\"Histogram of fraction of lost photons ({len(sim)} simulations)\")\n",
    "    # print info about flux, exposure time, Nimpacts, filter and focus\n",
    "    mean = np.mean(frac)\n",
    "    std = np.std(frac)\n",
    "    pm_str = u\"\\u00B1\"\n",
    "\n",
    "    # do a normality test\n",
    "    stat, p = shapiro(frac)\n",
    "    #print(\"Shapiro-Wilk test statistic: \", stat)\n",
    "    #print(\"Shapiro-Wilk test p-value: \", p)\n",
    "    # print a conclusion about the normality of the data\n",
    "    if not p > 0.05:\n",
    "        print(f\"For flux {flux_mcrab}: The fraction of lost photons is NOT normally distributed (shapiro test)\")\n",
    "    \n",
    "    # do an anderson-darling test for normality\n",
    "    result = anderson(frac)\n",
    "    #print(\"Anderson-Darling test statistic: \", result.statistic)\n",
    "    #print(\"Anderson-Darling test critical values: \", result.critical_values)\n",
    "    #print(\"Anderson-Darling test significance levels: \", result.significance_level)\n",
    "    #print(\"Anderson-Darling test p-value: \", result.significance_level[2])\n",
    "    # print a conclusion about normality\n",
    "    normality = True\n",
    "    if not result.statistic < result.critical_values[2]:\n",
    "        print(f\"For {flux_mcrab}: The fraction of lost photons is NOT normally distributed (anderson test)\")\n",
    "        normality = False\n",
    "    boxtext = (f\"Flux: {flux_mcrab}mCrab\\nExposure time: {exposure} s\\n\"\n",
    "               f\"sims: {nsims}\\n<Nimpacts>: {Nimpacts}\\n\"\n",
    "               f\"<Nmissing>: {Nmissing}\\nFilter: {filter}\\n\"\n",
    "               f\"Focus: {focus}\\nMean: {mean:.3f} {pm_str} {std:.3f}%\\n\"\n",
    "               f\"Anderson-Darling normality: {normality}\\n\")\n",
    "    ax[i].text(0.45, 0.55, boxtext, fontsize=10, transform=ax[i].transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the figure to PNG file\n",
    "fig.savefig(f\"{config_version}/Figures/normality/histograms_normality.png\", dpi=300)\n",
    "# save the figure to PDF file\n",
    "fig.savefig(f\"{config_version}/Figures/normality/histograms_normality.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distribution of fake pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import run\n",
    "extra_events = []\n",
    "# sort fluxes in ascending order\n",
    "fluxes = sorted(fluxes)\n",
    "for ifl in range(len(fluxes)):\n",
    "    flux = fluxes[ifl]\n",
    "    fluxDir = f\"flux{flux:.2f}mcrab\"\n",
    "    print(f\"Analyzing dir {fluxDir}\")\n",
    "    # check log files in the flux directory\n",
    "    logFiles = glob.glob(f\"{fluxDir}/sim_*.log\")\n",
    "    # check how many times logFiles contains the string \"extra\" preceeded by a number different from 0\n",
    "    extra = 0\n",
    "    # run 'grep' shell command to count the number of lines containing \"extra\" and not \"0\"\n",
    "    comm = f\"grep 'extra' {fluxDir}/sim_*.log | grep -v '0 (extra'\"\n",
    "    # run the command and capture the output\n",
    "    result = run(comm, shell=True, capture_output=True, text=True)\n",
    "    matching_lines = result.stdout.strip().split('\\n') if result.stdout else []\n",
    "    # get the numerical value from the matching lines\n",
    "    for line in matching_lines:\n",
    "        # split the line by whitespace and get the first element\n",
    "        # (the number of extra events)\n",
    "        extra += int(line.split()[1])\n",
    "    # append the number of extra events to the list\n",
    "    extra_events.append(extra)\n",
    "    # print the number of extra events\n",
    "    print(f\"                         Flux {flux:.2f} mCrab: {extra} extra events\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bar plot of the number of extra events for each flux\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(range(len(fluxes)), extra_events, color='blue', alpha=0.7)\n",
    "ax.set_xlabel(\"Flux [mCrab]\")\n",
    "ax.set_ylabel(\"Number of extra events\")\n",
    "ax.set_title(\"Number of extra events for each flux\")\n",
    "# label the x axis with the flux values\n",
    "ax.set_xticks(range(len(fluxes)))   \n",
    "ax.set_xticklabels([f\"{flux}\" for flux in fluxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the figure to PNG file\n",
    "fig.savefig(f\"{config_version}/Figures/normality/fake_detections.png\", dpi=300)\n",
    "# save the figure to PDF file\n",
    "fig.savefig(f\"{config_version}/Figures/normality/fake_detections.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSFCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
