{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0314a7c-1c8e-4a22-8213-d83cd7d2e80b",
   "metadata": {},
   "source": [
    "# XIFUSIM Simulation of a real source (model spectra)   \n",
    "\n",
    "It simulates a real source in all the pixels of X-IFU with `xifusim.`   \n",
    "The parameters that define the simulation are (* for mandatory):   \n",
    "    - Source flux in mCrab*   \n",
    "    - Source model*   \n",
    "    - filter* applied to defocused case:  `thinOpt` // `thickOpt` // `nofilt` // `thinBe` // `thickBe`   \n",
    "    - focus: `infoc` or `defoc`. If not provided `defoc` is applied to flux > 0.5 flux_mcrab and `infoc` otherwise       \n",
    "    - Lower energy in flux band (`Emin`): 2. keV   \n",
    "    - Upper energy in flux band (`Emax`): 10. keV   \n",
    "\n",
    "Other parameters (calculated/derived) are:   \n",
    "    - RA of source: 0.   \n",
    "    - Dec of source: 0.   \n",
    "    - Exposure time: x times the interval required to have 2 close pulses (assuming Poissonian)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fc31c",
   "metadata": {},
   "source": [
    "Possible models are:   \n",
    "1. `CRAB`    \n",
    "    Power law spectrum: $\\Gamma=2.05$      \n",
    "    Unabsorbed Flux(2-10keV): $21.6 \\times 10^{-12} \\rm{erg\\,cm^{-2}\\,s^{-1}}$     \n",
    "    Foregroung absorption: $N_H=2\\times 10^{21} \\rm{cm^{-2}}$    \n",
    "    XSPEC model: phabs*pegpwrlw   \n",
    "2. `EXTEND` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e71281-feba-415c-9f35-a42151b8939e",
   "metadata": {},
   "source": [
    "Simulation steps   \n",
    "1. Read simulation parameters and derived parameters   \n",
    "2. HEASOFT `xspec`: create xspec model file    \n",
    "3. SIXTE `simputfile`: Create simput file with photons distribution    \n",
    "4. SIXTE `sixtesim`: Run simulation to get   \n",
    "    4.1 ImpactList - piximpact file for ALL photons \n",
    "    4.2 EventList - which photons (PH_ID) impact in each pixel of the detector (including background)   \n",
    "    4.3 PixImpactList: piximpact file for each pixel with impacts (PH_ID) (needed by xifusim)   \n",
    "5. Get list of pixels w/ impacts. For each pixel with >1 impact:   \n",
    "    5.1. Check if there are \"close\" photons (otherwise skip xifusim simulation)   \n",
    "    5.2. Create a sub-piximpact file from the total piximpact file with the close photons\n",
    "    5.3. `xifusim`: Do single-pixel (NOMUX) xifusim simulation     \n",
    "    5.3. `sirena`: reconstruct xifusim simulation   \n",
    "    5.4. Analyse reconstruction to check for missing photons   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ce91bc",
   "metadata": {},
   "source": [
    "## Import routines and read parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade1182-95cf-47ad-b33f-c6392df08819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import run\n",
    "import sys\n",
    "import tempfile\n",
    "import glob\n",
    "\n",
    "import auxiliary as aux\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "#import heasoftpy as hsp\n",
    "import numpy as np\n",
    "import  pandas as pd\n",
    "from xspec import Xset, Model, AllModels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b7fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDir = tempfile.mkdtemp()\n",
    "os.environ[\"PFILES\"] = f\"{tmpDir}:{os.environ['PFILES']}\"\n",
    "os.environ[\"HEADASNOQUERY\"] = \"\"\n",
    "os.environ[\"HEADASPROMPT\"] = \"/dev/null/\"\n",
    "SIXTE = os.environ[\"SIXTE\"]\n",
    "xmldir = f\"{SIXTE}/share/sixte/instruments/athena-xifu/baseline\"\n",
    "xml = f\"{xmldir}/xifu_nofilt_infoc.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf29b2",
   "metadata": {},
   "source": [
    "### Read command-line parameters   \n",
    "```\n",
    "sim_number: simulation run number   \n",
    "flux_mcrab: erg/cm^2/s (1 mcrab=2.4E-11 erg/cm^2/s)   \n",
    "Emin: (keV) to define the energy range of the flux   \n",
    "Emax: (keV) to define the energy range of the flux   \n",
    "model: \"crab\"//TBD   \n",
    "filter:  thinOpt // thickOpt // nofilt // thinBe // thickBe    \n",
    "focus: '' (TBD from flux)   \n",
    "recons: 0 for no_reconstruction, 1 for do_reconstruction   \n",
    "verbose: 0 (silent) or 1 (chatty)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf108d4",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "sim_number = 1\n",
    "flux_mcrab = 0.5\n",
    "Emin = 2.\n",
    "Emax = 10.\n",
    "model = \"crab\"\n",
    "filter = \"nofilt\"\n",
    "focus = ''\n",
    "recons = 1\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbfea7",
   "metadata": {},
   "source": [
    "### Read derived/extra parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "RA=0.\n",
    "Dec=0.\n",
    "sampling_rate=130210 #Hz\n",
    "prebuff_xifusim=1500  #prebuffer samples for xifusim\n",
    "pileup_dist=30 #samples for pileup\n",
    "close_dist_toxifusim = 100 #samples for close events to decide if xifusim simulation will be done\n",
    "# 1 mCrab = 90 counts/s in the 2-10 keV band\n",
    "flux = flux_mcrab * 2.4E-11\n",
    "rate = flux_mcrab * 90 #counts/s\n",
    "time_30samps = pileup_dist/sampling_rate #s\n",
    "npile = 2 #counts \n",
    "npairs = 100 #pairs (close photons) to analyse pile-up\n",
    "aux.vprint(f\"rate={rate} ct/s, time_interval(30 samples)={time_30samps:.3e}s, npairs={npairs} pairs\")\n",
    "# get MAX number of PH_IDs in xifusim:\n",
    "# open file $SIXTE/../xifusim/libxifusim/WriteFile.h ang get numeric value in PH_IDs\n",
    "with open(f\"{SIXTE}/../xifusim/libxifusim/WriteFile.h\") as f:\n",
    "    for line in f:\n",
    "        if \"const unsigned int max_phids\" in line:\n",
    "            MAX_PHIDS_xifusim = line.split()[5]\n",
    "            # remove the last character (comma)\n",
    "            MAX_PHIDS_xifusim = int(MAX_PHIDS_xifusim[:-1])\n",
    "            break\n",
    "\n",
    "aux.vprint(f\"MAX_PHIDS_xifusim = {MAX_PHIDS_xifusim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672dc328",
   "metadata": {},
   "source": [
    "### Create folder structure for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new folder (if it does not exist) for the output using the flux as the name\n",
    "if flux_mcrab < 0.01:\n",
    "    flux_mcrab_str = f\"{flux_mcrab:.2e}\"\n",
    "else:\n",
    "    flux_mcrab_str = f\"{flux_mcrab:.2f}\"\n",
    "fluxDir = f\"flux{flux_mcrab_str}mcrab\"\n",
    "outDir = f\"{fluxDir}/sim_{sim_number}\"\n",
    "outDirPath = f\"{os.getcwd()}/{outDir}\"\n",
    "if not os.path.exists(outDirPath):\n",
    "    os.makedirs(outDirPath)\n",
    "log_file = f\"{fluxDir}/sim_{sim_number}.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea0731",
   "metadata": {},
   "source": [
    "### Set `sixtesim` XML file based on parameters (focus and filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set XML file based on parameters\n",
    "# if 'focus' is not provided: get it automatically according to the FLUX\n",
    "# Filter will only be applied to the defocussed case\n",
    "if focus == '':\n",
    "    if flux_mcrab <= 0.5:\n",
    "        focus=\"infoc\"\n",
    "        xml_sixtesim = f\"{xmldir}/xifu_nofilt_{focus}.xml\"\n",
    "    else:\n",
    "        focus=\"defoc\"\n",
    "        xml_sixtesim = f\"{xmldir}/xifu_{filter}_{focus}.xml\"\n",
    "elif focus == \"defoc\":\n",
    "    xml_sixtesim = f\"{xmldir}/xifu_{filter}_defoc.xml\"\n",
    "elif focus == \"infoc\":\n",
    "    xml_sixtesim = f\"{xmldir}/xifu_nofilt_infoc.xml\"\n",
    "\n",
    "if focus == \"defoc\":\n",
    "    npairs = npairs*50 # get more close pulses to have better statistics\n",
    "aux.vprint(f\"Using XML file: {xml_sixtesim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586b868",
   "metadata": {},
   "source": [
    "### get exposure time   \n",
    "required to get a good number of close photons (possible missing/bad-reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate exposure to get counts \n",
    "time_npairs = aux.time_to_observe_n_pairs(count_rate=rate, pairs_separation=time_30samps, npairs=npairs)\n",
    "exposure = time_npairs*20.1\n",
    "exposure_label = int(exposure)\n",
    "aux.vprint(f\"Using exposure time: {exposure:.2e}s\")\n",
    "aux.vprint(f\"Using exposure time label: {exposure_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02388daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set string to name files based on input parameters\n",
    "filestring_simput = f\"./{fluxDir}/{model}_flux{flux_mcrab_str}_Emin{Emin:.0f}_Emax{Emax:.0f}_RA{RA}_Dec{Dec}\"\n",
    "filestring = f\"./{outDir}/{model}_flux{flux_mcrab_str}_Emin{Emin:.0f}_Emax{Emax:.0f}_exp{exposure_label}_RA{RA}_Dec{Dec}_{filter}_{focus}\"\n",
    "#filestring = f\"{filestring_simput}_{filter}_{focus}\"\n",
    "print(filestring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeefc77-438d-4d3d-a874-8b0bf6241586",
   "metadata": {},
   "source": [
    "## Create XSPEC model file   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6093d15a-8aa5-4a21-a36d-abd6c94ab7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is spectral model file does not exist, create it\n",
    "if model == \"crab\":\n",
    "    xcm = f\"{model}.xcm\"\n",
    "    if not os.path.exists(xcm):\n",
    "        # Clear all models\n",
    "        AllModels.clear()\n",
    "        # define XSPEC parameters\n",
    "        Xset.abund = \"wilm\"\n",
    "        Xset.cosmo = \"70 0. 0.73\"\n",
    "        Xset.xsect = \"bcmc\"\n",
    "        mcmod = Model(\"phabs*pegpwrlw\")\n",
    "        mcmod.phabs.nH = 0.2\n",
    "        mcmod.pegpwrlw.PhoIndex = 2.05\n",
    "        mcmod.pegpwrlw.eMin = 2.\n",
    "        mcmod.pegpwrlw.eMax = 10.\n",
    "        mcmod.pegpwrlw.norm = 1.\n",
    "        #retrieve the flux value\n",
    "        AllModels.calcFlux(f\"{Emin} {Emax}\")\n",
    "        model_flux = AllModels(1).flux[0]\n",
    "        # calculate the new norm value\n",
    "        new_norm = flux/model_flux\n",
    "        mcmod.pegpwrlw.norm = new_norm\n",
    "        # Save the model to the specified .xcm file path\n",
    "        Xset.save(xcm)\n",
    "        aux.vprint(f\"Model saved to {xcm}\")\n",
    "else:\n",
    "    aux.vprint(\"Model not implemented yet\")\n",
    "    sys.exit(1)\n",
    "#mcmod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b8868",
   "metadata": {},
   "source": [
    "## Create simput file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bedc01-d766-46b6-9ee8-d65497b42e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run simputfile to create the simput file\n",
    "simputfile = f\"{filestring_simput}_simput.fits\"\n",
    "if not os.path.exists(simputfile):\n",
    "        comm = (f'simputfile Simput={simputfile} RA={RA} Dec={Dec} '\n",
    "                f'srcFlux={flux} Emin={Emin} Emax={Emax} '\n",
    "                f'XSPECFile={xcm} clobber=yes')\n",
    "        aux.vprint(f\"Running {comm}\")\n",
    "        # Run the command through the subprocess module\n",
    "        output_simputfile = run(comm, shell=True, capture_output=True)\n",
    "        #print(output_simputfile.stdout.decode())\n",
    "        assert output_simputfile.returncode == 0, f\"simputfile failed to run: {comm}\"\n",
    "        assert os.path.exists(simputfile), f\"simputfile did not produce an output file\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509515f",
   "metadata": {},
   "source": [
    "## Run sixtesim simulation: Create PIXIMPACT file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02634c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "evtfile = f\"{filestring}_evt.fits\"\n",
    "photfile = f\"{filestring}_photon.fits\"\n",
    "impfile = f\"{filestring}_impact.fits\"\n",
    "if not os.path.exists(evtfile) or not os.path.exists(photfile) or not os.path.exists(impfile):    \n",
    "        comm = (f'sixtesim PhotonList={photfile} Simput={simputfile} '\n",
    "                f'ImpactList={impfile} EvtFile={evtfile} '\n",
    "                f'XMLFile={xml_sixtesim} Background=yes RA={RA} Dec={Dec} ' \n",
    "                f'Exposure={exposure} clobber=yes')\n",
    "        aux.vprint(comm)\n",
    "        output_sixtesim = run(comm, shell=True, capture_output=True)\n",
    "        assert output_sixtesim.returncode == 0, f\"sixtesim failed to run\"\n",
    "        assert os.path.exists(evtfile), f\"sixtesim did not produce an output file\"\n",
    "        assert os.path.exists(photfile), f\"sixtesim did not produce an output file\"\n",
    "        assert os.path.exists(impfile), f\"sixtesim did not produce an output file\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c9075",
   "metadata": {},
   "source": [
    "## Do xifusim simulation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d8453a",
   "metadata": {},
   "source": [
    "### Get list of pixels with counts produced by sixtesim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a458af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verbose=1\n",
    "#read column PIXID from evtfile and save to a list of unique pixels\n",
    "hdulist = fits.open(evtfile, mode='update')\n",
    "evtdata = hdulist[1].data\n",
    "pixels_with_impacts = np.unique(evtdata['PIXID']) #photons coming from sources (PH_ID>-1) and background (PH_ID=-1)\n",
    "aux.vprint(f\"Number of pixels with impacts: {len(pixels_with_impacts)}\")\n",
    "# all bkg impacts have same PH_ID identifier (-1)\n",
    "# if more than one event with PH_ID=-1, change PH_ID of bkg impacts: if PH_ID==-1, change to consecutive negative number\n",
    "if len(evtdata['PH_ID'][evtdata['PH_ID'] == -1]) > 1:\n",
    "    phid_bkg = -1\n",
    "    for i in range(len(evtdata)):\n",
    "        if evtdata['PH_ID'][i] == -1:\n",
    "            evtdata['PH_ID'][i] = phid_bkg\n",
    "            phid_bkg -= 1\n",
    "    #save changes to evtfile\n",
    "hdulist.close()\n",
    "\n",
    "# get pixels used and the events in each pixel\n",
    "nimpacts_inpix = dict()\n",
    "phid_impacts_inpix = dict()\n",
    "for pixel in pixels_with_impacts:\n",
    "    phid_impacts_inpix[pixel] = evtdata['PH_ID'][evtdata['PIXID'] == pixel]\n",
    "    nimpacts_inpix[pixel] = len(phid_impacts_inpix[pixel])\n",
    "\n",
    "#print number of impacts per pixel sorted by number of impacts\n",
    "for key, value in sorted(nimpacts_inpix.items(), key=lambda item: item[1], reverse=True):\n",
    "    aux.vprint(f\"Pixel {key}: {value} impacts\")\n",
    "\n",
    "\n",
    "#print the PH_ID of impacts in pixels\n",
    "for key, value in phid_impacts_inpix.items():\n",
    "    aux.vprint(f\"Pixel {key}: \")\n",
    "    aux.vprint(f\"      PH_ID:{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b01e2",
   "metadata": {},
   "source": [
    "### Read sixtesim output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bd6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open sixtesim ImpactList and read data \n",
    "hdulist = fits.open(impfile)\n",
    "impdata = hdulist[1].data\n",
    "hdulist.close()\n",
    "# open sixtesim EvtList and read data (has been modified to include different PH_ID for background photons)\n",
    "hdulist = fits.open(evtfile)\n",
    "evtdata = hdulist[1].data\n",
    "hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154feca0",
   "metadata": {},
   "source": [
    "### For each pixel with impacts, do a xifusim simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3def90",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.vprint(pixels_with_impacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e778a",
   "metadata": {},
   "source": [
    "#### Extract a piximpact file for each interesting pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4466d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ipixel in pixels_with_impacts:\n",
    "    aux.vprint(f\"Checking existence of piximpact file for pixel {ipixel}\")\n",
    "    # create a subsample of the piximpact file selecting only those rows where PH_ID is in \n",
    "    # the list of the impacts in the pixel\n",
    "    piximpactfile = f\"{filestring}_pixel{ipixel}_piximpact.fits\"\n",
    "    \n",
    "    # if file does not exist, create it\n",
    "    if not os.path.exists(piximpactfile):\n",
    "        # copy src impacts from impact file and bkgs from event file\n",
    "        # background are not in the impact list (only in the event file)\n",
    "        phid_impacts_inpix_srcs = phid_impacts_inpix[ipixel][phid_impacts_inpix[ipixel] > 0]\n",
    "        \n",
    "        # if there are no source impacts in the pixel, create a new table with only the background\n",
    "        if len(phid_impacts_inpix_srcs) > 0:  # src impacts\n",
    "            # create a mask to select only the rows with the impacts in this pixel\n",
    "            mask = np.isin(impdata['PH_ID'], phid_impacts_inpix_srcs)\n",
    "            # create a new table with the selected rows\n",
    "            newtable = Table(impdata[mask])\n",
    "        else: # create table to include only background impacts\n",
    "            aux.vprint(f\"No source impacts in pixel {ipixel}\")\n",
    "            newtable = Table()\n",
    "            # add columns TIME, SIGNAL, PH_ID and SRCID\n",
    "            newtable['TIME'] = []\n",
    "            newtable['ENERGY'] = []\n",
    "            newtable['PH_ID'] = []\n",
    "            newtable['SRC_ID'] = []\n",
    "            \n",
    "        # add the background impacts to the new table based on data in the event file\n",
    "        # get indices of rows from event file where PH_ID < 0 (background)\n",
    "        #   if 0.15keV < ENERGY < 0.2 keV => in EVT file: ENERGY = 0  => \n",
    "        # #    in pixelimpact will inherit ENERGY = 0 AND THEY WILL NOT BE SIMULATED BY XIFUSIM\n",
    "        #   ** ARF/RMF threshold = 0.15keV but X-IFU/XML readout threshold=0.2keV **\n",
    "        bkg_indices = np.where(evtdata['PH_ID'] < 0)[0]\n",
    "        for ibkg in bkg_indices:\n",
    "            if evtdata['PIXID'][ibkg] != ipixel:\n",
    "                continue\n",
    "            # create a new row in the new table\n",
    "            newtable.add_row()\n",
    "            # copy the bkg values from the event file (columns TIME, SIGNAL, PH_ID and SRCID) \n",
    "            # to the new table (to columns TIME, ENERGY, PH_ID and SRCID)\n",
    "            # Check first if newtable is empty (no source impacts)\n",
    "            if len(newtable) == 0:\n",
    "                newtable['TIME'] = evtdata['TIME'][ibkg]\n",
    "                newtable['ENERGY'] = evtdata['SIGNAL'][ibkg] # if 0.15 < ENERGY <0.2 => ENERGY=0 in piximapct => not xifusim\n",
    "                newtable['PH_ID'] = evtdata['PH_ID'][ibkg]\n",
    "                newtable['SRC_ID'] = evtdata['SRC_ID'][ibkg]\n",
    "            else:\n",
    "                newtable['TIME'][-1] = evtdata['TIME'][ibkg]\n",
    "                newtable['ENERGY'][-1] = evtdata['SIGNAL'][ibkg] # if 0.15 < ENERGY <0.2 => ENERGY=0 in piximapct => not xifusim\n",
    "                newtable['PH_ID'][-1] = evtdata['PH_ID'][ibkg]\n",
    "                newtable['SRC_ID'][-1] = evtdata['SRC_ID'][ibkg]\n",
    "        # sort newtable according to TIME\n",
    "        newtable.sort('TIME')\n",
    "            \n",
    "        # add new columns X,Y,U,V, GRADE1, GRADE2, TOTALEN with the value 0 and PIXID with the value of ipixel\n",
    "        newtable['X'] = 0.\n",
    "        newtable['Y'] = 0.\n",
    "        newtable['U'] = 0.\n",
    "        newtable['V'] = 0.\n",
    "        newtable['GRADE1'] = 0\n",
    "        newtable['GRADE2'] = 0\n",
    "        newtable['TOTALEN'] = 0\n",
    "        newtable['PIXID'] = ipixel\n",
    "\n",
    "        # name the new table 'PIXELIMPACT'\n",
    "        newtable.meta['EXTNAME'] = 'PIXELIMPACT'\n",
    "    \n",
    "        # write the new table to a new FITS file\n",
    "        newtable.write(piximpactfile, format='fits', overwrite=True)\n",
    "\n",
    "        # print the name of the new file rewriting the output line\n",
    "        aux.vprint(f\"Created {piximpactfile} for pixel {ipixel}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dcab92",
   "metadata": {},
   "source": [
    "### Get XML for xifusim simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe29a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find name of (unique) xml file in indir directory\n",
    "xml_xifusim = glob.glob(f\"./config*.xml\")\n",
    "if len(xml_xifusim) != 1:\n",
    "    raise FileNotFoundError(f\"Error: expected 1 XML file but found {len(xml_xifusim)}\")\n",
    "xml_xifusim = xml_xifusim[0]\n",
    "aux.vprint(f\"Using XIFUSIM XML file: {xml_xifusim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193b965",
   "metadata": {},
   "source": [
    "### Run the xifusim simulation (with XML for single pixel)   \n",
    "    - simulate time between min and max TIME in piximpact   \n",
    "    - set PIXID to '1' for simulation   \n",
    "    - xifusim simulation    \n",
    "    - re-establish correct PIXID    \n",
    "    - get the number of phsims in the pixel: check different values in PH_ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each piximpact file, run xifusim\n",
    "prebuffer = 1500\n",
    "phsims_inpix = dict()\n",
    "nphsims_inpix = dict()\n",
    "skipped_photons_inpix = dict()\n",
    "skipped_xifusim = []   \n",
    "\n",
    "for ipixel in pixels_with_impacts:\n",
    "    aux.vprint(\"====================================\")\n",
    "    aux.vprint(f\"Selecting photons for pixel {ipixel}\")\n",
    "    aux.vprint(\"====================================\")\n",
    "    # get total number of simulated photons in the pixel\n",
    "    piximpactfile = f\"{filestring}_pixel{ipixel}_piximpact.fits\"\n",
    "    with fits.open(piximpactfile) as hdulist_piximpact:\n",
    "        piximpactdata = hdulist_piximpact[1].data.copy()\n",
    "    phsims_inpix[ipixel] =  piximpactdata['PH_ID']\n",
    "    nphsims_inpix[ipixel] = len(phsims_inpix[ipixel])\n",
    "\n",
    "    # if no more than 1 impact in the pixel, skip the simulation\n",
    "    if nimpacts_inpix[ipixel] <= 1:\n",
    "        aux.vprint(f\"  Skipping simulation for pixel {ipixel} with {nimpacts_inpix[ipixel]} impact\")\n",
    "        skipped_xifusim.append(ipixel)\n",
    "        continue\n",
    "    \n",
    "    # if there is no xifusim file for the pixel, create it\n",
    "    xifusimfile = f\"{filestring}_pixel{ipixel}_xifusim.fits\"\n",
    "    if not os.path.exists(xifusimfile):\n",
    "        # check if there are close events in the pixel\n",
    "        aux.vprint(f\"  Checking if needed simulation for pixel {ipixel} with {nimpacts_inpix[ipixel]} impact\")\n",
    "        PH_ID_toxifusim = []\n",
    "        PH_ID_skipped = []\n",
    "        time_diff = np.diff(piximpactdata['TIME'])\n",
    "        close_photons = time_diff < close_dist_toxifusim / sampling_rate\n",
    "\n",
    "        for i in range(len(piximpactdata)):\n",
    "            if ((i == 0 and close_photons[i]) or  \n",
    "                (i == len(piximpactdata) - 1 and close_photons[i - 1]) or \n",
    "                (0 < i < len(piximpactdata) - 1 and (close_photons[i] or close_photons[i - 1]))):\n",
    "                PH_ID_toxifusim.append(piximpactdata['PH_ID'][i])\n",
    "                aux.vprint(f\"  Photon {piximpactdata['PH_ID'][i]} is close to another photon previous or next in time\")\n",
    "            else:\n",
    "                PH_ID_skipped.append(piximpactdata['PH_ID'][i])\n",
    "\n",
    "        skipped_photons_inpix[ipixel] = PH_ID_skipped\n",
    "        #aux.vprint(f\"{len(PH_ID_toxifusim)} Photons for xifusim: {PH_ID_toxifusim}\")\n",
    "        #aux.vprint(f\"{len(PH_ID_skipped)} Skipped photons in pixel {ipixel}: {skipped_photons_inpix[ipixel]}\")\n",
    "        aux.vprint(f\"    {len(PH_ID_skipped)} Skipped photons in pixel {ipixel}\")\n",
    "        aux.vprint(f\"    {len(PH_ID_toxifusim)} Photons for xifusim\")\n",
    "\n",
    "        # if no photons closer than close_dist_toxifusim/sampling_rate (secs) in the pixel, skip the simulation \n",
    "        if len(PH_ID_toxifusim) == 0:\n",
    "            aux.vprint(f\"    No photons closer than {close_dist_toxifusim} samples in pixel {ipixel}: skipping simulation\")\n",
    "            skipped_xifusim.append(ipixel)\n",
    "            continue\n",
    "        \n",
    "        # create a new (reduced) FITS piximpact file keeping only those PH_ID ...\n",
    "        # ... where TIME of photons is closer than close_dist_toxifusim (samples)\n",
    "        piximpactfile_toxifusim = f\"{filestring}_pixel{ipixel}_piximpact_toxifusim.fits\"\n",
    "        if not os.path.exists(piximpactfile_toxifusim):\n",
    "            # create a new table with the selected rows\n",
    "            #mask = np.isin(piximpactdata['PH_ID'], PH_ID_toxifusim[PH_ID_toxifusim != 0])\n",
    "            mask = np.isin(piximpactdata['PH_ID'], PH_ID_toxifusim)\n",
    "            newtable = Table(piximpactdata[mask])\n",
    "            # replace PIXID column with value '1' (xifusim requirement)\n",
    "            newtable['PIXID'] = 1\n",
    "            # name the new table 'PIXELIMPACT'\n",
    "            newtable.meta['EXTNAME'] = 'PIXELIMPACT'\n",
    "            # write the new table to a new FITS file\n",
    "            newtable.write(piximpactfile_toxifusim, format='fits', overwrite=True)\n",
    "            aux.vprint(f\"  Created {piximpactfile_toxifusim} for pixel {ipixel}\")\n",
    "\n",
    "        # use reduced piximpact file to run xifusim\n",
    "        with fits.open(piximpactfile_toxifusim) as hdulist_toxifusim:\n",
    "            piximpactdata_toxifusim = hdulist_toxifusim[1].data.copy()\n",
    "        #calculate minimum and maximum time for impacts in the pixel\n",
    "        mintime = np.min(piximpactdata_toxifusim['TIME'])\n",
    "        maxtime = np.max(piximpactdata_toxifusim['TIME'])\n",
    "        expos_init = mintime - 2.*prebuff_xifusim/sampling_rate\n",
    "        expos_fin = maxtime + 0.1\n",
    "        \n",
    "        #create xifusim name based on input parameters    \n",
    "        comm = (f'xifusim PixImpList={piximpactfile_toxifusim} Streamfile={xifusimfile} '\n",
    "                f'tstart={expos_init} tstop={expos_fin} '\n",
    "                f'trig_reclength=12700 '\n",
    "                f'trig_n_pre={prebuff_xifusim} '\n",
    "                f'trig_n_suppress=8192 '\n",
    "                f'trig_maxreclength=100000 '\n",
    "                f'XMLfilename={xml_xifusim} clobber=yes ')\n",
    "        \n",
    "        aux.vprint(f\"  Doing simulation for pixel {ipixel} with {len(piximpactdata_toxifusim)} impacts ({nimpacts_inpix[ipixel]} TOTAL impacts)\")\n",
    "        #aux.vprint(f\"Running {comm}\")\n",
    "        output_xifusim = run(comm, shell=True, capture_output=True)\n",
    "        assert output_xifusim.returncode == 0, f\"xifusim failed to run: {comm}\"\n",
    "        assert os.path.exists(xifusimfile), f\"xifusim did not produce an output file\"\n",
    "\n",
    "        # re-write correct PIXID in the xifusim file\n",
    "        with fits.open(xifusimfile, mode='update') as hdulist:\n",
    "            xifusimdata = hdulist[\"TESRECORDS\"].data\n",
    "            xifusimdata['PIXID'] = ipixel\n",
    "            hdulist.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801d528",
   "metadata": {},
   "source": [
    "## DO reconstruction with SIRENA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d09a12",
   "metadata": {},
   "source": [
    "### get LIBRARY adequate to XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find name of (unique) library file in indir directory compatible with xifusim XML file\n",
    "lib_sirena = glob.glob(f\"./*library*\")\n",
    "if len(lib_sirena) != 1:\n",
    "    raise FileNotFoundError(f\"Expected 1 LIBRARY file but found {len(lib_sirena)}\")\n",
    "lib_sirena = lib_sirena[0]\n",
    "aux.vprint(f\"Using LIBRARY file: {lib_sirena}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ef7c9",
   "metadata": {},
   "source": [
    "### run `tesrecons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecc036",
   "metadata": {},
   "outputs": [],
   "source": [
    "if recons:\n",
    "    for ipixel in pixels_with_impacts:\n",
    "        # if pixel was skipped in xifusim, skip reconstruction\n",
    "        if ipixel in skipped_xifusim:\n",
    "            continue\n",
    "        xifusimfile = f\"{filestring}_pixel{ipixel}_xifusim.fits\"\n",
    "        reconsfile = f\"{filestring}_pixel{ipixel}_sirena.fits\"\n",
    "        if os.path.exists(reconsfile):\n",
    "            # check that all PH_ID rows have at least one zero element \n",
    "            # (previos versions of SIRENA had a limitation of 3 values even if there were more detections)\n",
    "            # if not, run again\n",
    "            with fits.open(reconsfile) as hdulist_recons:\n",
    "                reconsdata = hdulist_recons[1].data.copy()\n",
    "            # check if all PH_ID rows have at least one zero element\n",
    "            # get PH_ID values from the reconsdata\n",
    "            phid_recons = reconsdata['PH_ID']\n",
    "            # get the number of unique PH_ID values\n",
    "            unique_phid_recons = np.unique(phid_recons)\n",
    "            # check if a '0' is present in the PH_ID values\n",
    "            # if not, run again\n",
    "            if 0 not in unique_phid_recons:\n",
    "                aux.vprint(f\"Reconstruction file {reconsfile} does not have a zero PH_ID: possibly not listing all detections\")\n",
    "                aux.vprint(f\"Reconstruction file {reconsfile} will be removed\")\n",
    "                # remove the file\n",
    "                os.remove(reconsfile)\n",
    "            else:\n",
    "                aux.vprint(f\"Reconstruction file {reconsfile} already exists: skipping reconstruction\")\n",
    "                continue\n",
    "\n",
    "        if not os.path.exists(reconsfile):\n",
    "            comm = (f\"tesrecons Recordfile={xifusimfile} \"\n",
    "                f\" TesEventFile={reconsfile}\"\n",
    "                f\" LibraryFile={lib_sirena}\"\n",
    "                f\" XMLFile={xml_xifusim}\"\n",
    "                f\" clobber=yes\"\n",
    "                f\" EnergyMethod=OPTFILT\"\n",
    "                f\" OFStrategy=BYGRADE\"\n",
    "                f\" filtEeV=6000\"\n",
    "                f\" OFNoise=NSD\"\n",
    "            )\n",
    "            aux.vprint(f\"Doing reconstruction for pixel {ipixel}\", end='\\r')\n",
    "            #aux.vprint(f\"Running {comm}\")\n",
    "            output_tesrecons = run(comm, shell=True, capture_output=True)\n",
    "            assert output_tesrecons.returncode == 0, f\"tesrecons failed to run:{comm}\"\n",
    "            assert os.path.exists(reconsfile), f\"tesrecons did not produce an output file\"\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74afecd",
   "metadata": {},
   "source": [
    "### Try to IDENTIFY detected photons in SIRENA based on PIXIMPACT time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to SIRENA file with a possible ID of the photons (based on time in the piximact file)   \n",
    "# open the SIRENA file and read the data\n",
    "for ipixel in pixels_with_impacts:\n",
    "    # if pixel was skipped in xifusim, skip reconstruction\n",
    "    if ipixel in skipped_xifusim:\n",
    "        continue\n",
    "    reconsfile = f\"{filestring}_pixel{ipixel}_sirena.fits\"\n",
    "    # open the piximpact file and read the data\n",
    "    piximpactfile = f\"{filestring}_pixel{ipixel}_piximpact.fits\"\n",
    "    with fits.open(piximpactfile) as hdulist_piximpact:\n",
    "        piximpactdata = hdulist_piximpact[1].data\n",
    "        piximpact_phids = piximpactdata['PH_ID'].copy()\n",
    "\n",
    "    # if PROBPHID does not exist add a new column to the SIRENA file with the name 'PROBPHID'\n",
    "    with fits.open(reconsfile, mode='update') as hdulist_recons:\n",
    "        # read the data from the SIRENA file\n",
    "        EVENTS_hdu = hdulist_recons[1]\n",
    "        reconsdata = EVENTS_hdu.data\n",
    "        cols = EVENTS_hdu.columns\n",
    "        # check if the column already exists\n",
    "        if not 'PROBPHID' in cols.names:\n",
    "            aux.vprint(f\"Adding PROBPHID column to {reconsfile}\")\n",
    "            col_PROBPHID = fits.Column(name='PROBPHID', format='J', unit='', array=np.zeros(len(reconsdata), dtype=int))\n",
    "            new_cols = fits.ColDefs(cols + col_PROBPHID)\n",
    "            # create a new BinTableHDU with the new columns\n",
    "            new_hdu = fits.BinTableHDU.from_columns(new_cols)\n",
    "            # name the new HDU 'EVENTS'\n",
    "            new_hdu.name = 'EVENTS'\n",
    "            # replace the old table with the new one\n",
    "            hdulist_recons[1] = new_hdu\n",
    "            hdulist_recons.flush()\n",
    "\n",
    "    # Check if column PROBPHID does not have any '0' values (already populated): then skip to new pixel\n",
    "    with fits.open(reconsfile) as hdulist_recons:\n",
    "        reconsdata = hdulist_recons[1].data\n",
    "        cols = hdulist_recons[1].columns\n",
    "        probphid = reconsdata['PROBPHID']\n",
    "        # check if all values are '0' (initialized but not updated)\n",
    "        if np.all(probphid == 0):\n",
    "            aux.vprint(f\"PROBPHID column in {reconsfile} has '0' values: will be updated\")\n",
    "        else:\n",
    "            aux.vprint(f\"PROBPHID column in {reconsfile} already exists and it is populated: skipping update\")\n",
    "            continue\n",
    "\n",
    "    # if '0' values are present: update the PROBPHID column with the best guess of the PH_ID\n",
    "    with fits.open(reconsfile, mode='update') as hdulist_recons:\n",
    "        reconsdata = hdulist_recons[1].data\n",
    "        PH_ID = reconsdata['PH_ID']\n",
    "        TIME = reconsdata['TIME']\n",
    "        GRADE2 = reconsdata['GRADE2']\n",
    "        # for each event in the SIRENA file, check if it is close to an event in the piximpact file\n",
    "        for irow in range(len(reconsdata)):\n",
    "            ph_nonzero_sequence = PH_ID[irow][np.nonzero(PH_ID[irow])]\n",
    "            number_of_ph_zeros = len(PH_ID[irow]) - len(ph_nonzero_sequence)\n",
    "            # if number of values == 0 in PH_ID[irow] is 0, then max number of detections reached: some photons may be not registered in PH_ID\n",
    "            if number_of_ph_zeros == 0:\n",
    "                message = f\"Maximum number of photons reached in row {irow}: some photons may have not been registered in PH_ID\"\n",
    "                print(f\"*** ERROR: {message}\")\n",
    "                raise ValueError(f\"{message}\")\n",
    "            \n",
    "            time_sirena = TIME[irow]\n",
    "            \n",
    "            # if number of values != 0 in PH_ID[irow] is 1, then it is a single photon\n",
    "            if len(ph_nonzero_sequence) == 1:\n",
    "                # single photon\n",
    "                ph_id_i = PH_ID[irow][0]\n",
    "            else:\n",
    "                # more than one photon in the record: check corresponding time in impact file\n",
    "                min_time_diff = float('inf')\n",
    "                for ph_id in ph_nonzero_sequence:\n",
    "                    # get the time of the photon in the impact file: same PH_ID \n",
    "                    index_match = np.where((piximpactdata['PH_ID'] == ph_id))\n",
    "                    # check if there is a match\n",
    "                    if len(index_match[0]) == 0:\n",
    "                        raise ValueError(f\"PH_ID {ph_id} not found in impact file\")\n",
    "                    time_ph_piximpact = piximpactdata['TIME'][index_match]\n",
    "                    time_diff = abs(time_ph_piximpact - time_sirena)\n",
    "                    # check if the time difference is smaller than the minimum time difference\n",
    "                    # if so, update the minimum time difference and the PH_ID\n",
    "                    if time_diff < min_time_diff:\n",
    "                        min_time_diff = time_diff\n",
    "                        ph_id_i = ph_id\n",
    "            # Update GRADE2 if necessary\n",
    "            # get the time of the previous photon in the impact file (time ordered)\n",
    "            index_prev = np.where((piximpactdata['PH_ID'] == ph_id_i))[0] - 1\n",
    "            if index_prev >= 0:\n",
    "                time_prevph_piximpact = piximpactdata['TIME'][index_prev]\n",
    "                samples_dist_prev = abs(time_prevph_piximpact - time_sirena)*sampling_rate\n",
    "                # take the separation time from piximpact and update GRADE2 if it is different\n",
    "                if abs(samples_dist_prev - GRADE2[irow]) > 5:\n",
    "                    reconsdata['GRADE2'][irow] = samples_dist_prev\n",
    "            \n",
    "            # Update PROBPHID with the PH_ID of the photon\n",
    "            reconsdata['PROBPHID'][irow] = ph_id_i\n",
    "        # save changes to the SIRENA file\n",
    "        hdulist_recons.flush()\n",
    "        aux.vprint(f\"Updated PROBPHID and GRADE2 column in {reconsfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c69644",
   "metadata": {},
   "source": [
    "### check missing or misreconstructed photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed information about missing photons for the simulation (for each pixel)\n",
    "if recons:\n",
    "    # save info to pandas table\n",
    "    # Column 1: pixel ID (integer)\n",
    "    # Column 2: bad-reconstructed photons (integer)\n",
    "    # Column 3: non-reconstructed photons (integer)\n",
    "    # Column 4: grade1 of bad-reconstructed photons (integer)\n",
    "    # Column 5: grade2 of bad-reconstructed photons (integer)\n",
    "    info_table = pd.DataFrame(columns=['Pixel',  'Bad-reconstructed photons', 'Bad-reconstructed photons energy', \n",
    "                                       'Non-reconstructed photons', 'Non-reconstructed photons energies',\n",
    "                                       'GRADE1 Bad-recons', 'GRADE2 Bad-recons'], dtype=object)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if recons:\n",
    "    # reset skipped photons (just in case, photon separation criteria changed in xifusim simulations)\n",
    "    skipped_photons_inpix = dict()\n",
    "    \n",
    "    # Check how many photons were reconstructed: compare the number of impacts in the pixel with the number of reconstructed photons\n",
    "    ph_non_recons_inpix = dict()\n",
    "    ph_bad_recons_inpix = dict()\n",
    "    nextra_recons_inpix = dict()\n",
    "    nbad_recons_inpix = dict()\n",
    "    nnon_recons_inpix = dict()\n",
    "    nrecons_inpix = dict()\n",
    "    \n",
    "    nrecons_total = 0\n",
    "    nimpacts_total = 0\n",
    "    nbad_recons_total = 0\n",
    "    nnon_recons_total = 0\n",
    "    \n",
    "    for ipixel in pixels_with_impacts:\n",
    "        #if not ipixel == 161:\n",
    "        #    continue\n",
    "        # if pixel was skipped in xifusim (1 impact or separated impacts)\n",
    "        if ipixel in skipped_xifusim:\n",
    "            # get the number of reconstructed photons\n",
    "            nrecons_inpix[ipixel] = nphsims_inpix[ipixel] \n",
    "            nextra_recons_inpix[ipixel] = 0  \n",
    "            ph_non_recons_inpix[ipixel] = np.array([])\n",
    "            ph_bad_recons_inpix[ipixel] = np.array([])\n",
    "            nnon_recons_inpix[ipixel] = 0\n",
    "            nbad_recons_inpix[ipixel] = 0\n",
    "        else:\n",
    "            nextra_recons_inpix[ipixel] = 0\n",
    "            missing_for_badrecons = dict()\n",
    "            energies_missing_for_badrecons = dict()\n",
    "            #read SIRENA file\n",
    "            reconsfile = f\"{filestring}_pixel{ipixel}_sirena.fits\"\n",
    "            hdulist = fits.open(reconsfile)\n",
    "            reconsdata = hdulist[1].data\n",
    "            PH_ID = reconsdata['PH_ID'].copy()\n",
    "            GRADE1 = reconsdata['GRADE1'].copy()\n",
    "            GRADE2 = reconsdata['GRADE2'].copy()\n",
    "            PROBPHID = reconsdata['PROBPHID'].copy()\n",
    "            hdulist.close()\n",
    "\n",
    "            # read PIXIMPACT file (for TIME column)\n",
    "            hdulist = fits.open(f\"{filestring}_pixel{ipixel}_piximpact.fits\")\n",
    "            piximpactdata = hdulist[1].data.copy()\n",
    "            piximpact_phids = piximpactdata['PH_ID'].copy()\n",
    "            hdulist.close()\n",
    "            # read PIXIMPACT_toxifusim file \n",
    "            hdulist = fits.open(f\"{filestring}_pixel{ipixel}_piximpact_toxifusim.fits\")\n",
    "            piximpact_toxifusim_data = hdulist[1].data.copy()\n",
    "            piximpact_toxifusim_phids = piximpact_toxifusim_data['PH_ID'].copy()\n",
    "            hdulist.close()\n",
    "\n",
    "            # set the skipped photons as the difference between PH_IDs in piximapct and in piximpact_toxifusim\n",
    "            skipped_photons_inpix[ipixel] = np.setdiff1d(piximpact_phids, piximpact_toxifusim_phids)\n",
    "            # get the number of reconstructed photons\n",
    "            nrecons_inpix[ipixel] = len(reconsdata) + len(skipped_photons_inpix[ipixel])\n",
    "\n",
    "            # inititalize the lists of photons \n",
    "            ph_non_recons_inpix[ipixel] = phsims_inpix.get(ipixel, [])\n",
    "            ph_bad_recons_inpix[ipixel] = np.array([])\n",
    "            nnon_recons_inpix[ipixel] = 0\n",
    "            nbad_recons_inpix[ipixel] = 0\n",
    "\n",
    "            aux.vprint(f\"Pixel {ipixel}: \")\n",
    "            aux.vprint(f\"      {nimpacts_inpix[ipixel]} impacts\")\n",
    "            aux.vprint(f\"      {nphsims_inpix[ipixel]} simulated photons\")\n",
    "            aux.vprint(f\"      {nrecons_inpix[ipixel]} (inititally)reconstructed photons\")\n",
    "\n",
    "            irows_checked = []\n",
    "            for irow in range(len(PH_ID)):\n",
    "                if irow in irows_checked:\n",
    "                    aux.vprint(f\"    SIRENA: row {irow+1} in pixel {ipixel} already checked\")\n",
    "                    continue\n",
    "                \n",
    "                aux.vprint(f\"SIRENA: Checking row {irow+1} in pixel {ipixel}\")\n",
    "                # get number of values in the array PH_ID[irow] that are /= 0\n",
    "                nphotons_in_sirena_record = np.count_nonzero(PH_ID[irow])\n",
    "                nzeros_in_sirena_record = len(PH_ID[irow]) - nphotons_in_sirena_record\n",
    "                aux.vprint(f\"    SIRENA: PH_ID[row={irow+1}]: {PH_ID[irow]}\")\n",
    "                \n",
    "                if nphotons_in_sirena_record == 1:\n",
    "                    # remove PH_ID[irow] value from the list of non-reconstructed photons\n",
    "                    aux.vprint(f\"    SIRENA: Removing photon {PH_ID[irow][0]} from the list of non-reconstructed photons\")\n",
    "                    ph_non_recons_inpix[ipixel] = np.delete(ph_non_recons_inpix[ipixel], np.where(ph_non_recons_inpix[ipixel] == PH_ID[irow][0]))\n",
    "                else:\n",
    "                    # check which photons in record are not reconstructed\n",
    "                    ph_full_sequence_sirena = PH_ID[irow][np.nonzero(PH_ID[irow])]\n",
    "                    if nzeros_in_sirena_record == 0:\n",
    "                        # save message in log_file\n",
    "                        with open(log_file, \"a\") as f:\n",
    "                            message = f\"Error: MAX_PHIDs in xifusim/sirena reached in pixel {ipixel}: execution stopped\\n\"\n",
    "                            f.write(message)\n",
    "                            # stop execution\n",
    "                            raise ValueError(message)\n",
    "                    # get all the indices of the SIRENA rows with the same values as PH_ID[irow] (all the detections)\n",
    "                    indices_same_photons = np.where((PH_ID == PH_ID[irow]).all(axis=1))[0]\n",
    "                    aux.vprint(f\"    SIRENA: rows with same photons: {indices_same_photons+1}\")\n",
    "                    # add indices_same_photons values to the list of checked rows\n",
    "                    irows_checked.extend(indices_same_photons)\n",
    "                    \n",
    "                    if len(indices_same_photons) < nphotons_in_sirena_record:\n",
    "                        aux.vprint(f\"    SIRENA: Warning: missed {nphotons_in_sirena_record - len(indices_same_photons)} photons in the list {PH_ID[irow]}\")\n",
    "                        # try to identify missed photon(s) looking at the TIME column\n",
    "                        closest_sirena_row_for_photon = dict()\n",
    "                        timediff_sirena_row_for_photon = dict()\n",
    "                        \n",
    "                        for ph in ph_full_sequence_sirena:\n",
    "                            # look for the photon in the piximpact file and get TIME value\n",
    "                            idx_ph = np.where(piximpactdata['PH_ID'] == ph)[0]\n",
    "                            time_ph_piximpact = piximpactdata['TIME'][idx_ph]\n",
    "                            # look for the photon in the SIRENA file and get TIME value: compare with TIME in piximpact file\n",
    "                            # assignate the closest SIRENA photon to the XIFUSIM photon\n",
    "                            min_time_diff = float('inf')\n",
    "                            for idx in indices_same_photons:\n",
    "                                time_ph_sirena = reconsdata['TIME'][idx]\n",
    "                                time_diff = abs(time_ph_piximpact-time_ph_sirena)\n",
    "                                if time_diff < min_time_diff:\n",
    "                                    min_time_diff = time_diff\n",
    "                                    closest_sirena_row_for_photon[ph] = idx\n",
    "                                    timediff_sirena_row_for_photon[ph] = time_diff                        \n",
    "                        aux.vprint(f\"    SIRENA: closest sirena row for photons[photon_PH_ID:SIRENA_rowIndex]: {closest_sirena_row_for_photon}\")\n",
    "                        # check that number of unique xifusim_sirena_photons values is consistent with SIRENA detected photons\n",
    "                        if len(indices_same_photons) != len(set(closest_sirena_row_for_photon.values())):                            \n",
    "                            raise ValueError(f\"Error: Incorrect assignation of SIRENA rows to XIFUSIM photons - check assignation time interval\")\n",
    "                        \n",
    "                        # look if the xifusim_sirena_photons dictionary has duplicated values: identify keys with the same value\n",
    "                        sirena_detections_rows = list(closest_sirena_row_for_photon.values())\n",
    "                        xifusim_phs = list(closest_sirena_row_for_photon.keys())\n",
    "                        unique_sirena_detections = list(set(sirena_detections_rows))\n",
    "                        # identify the xifusim photons with same sirena identification\n",
    "                        # loop over the indices of unique sirena_phs:\n",
    "                        for uni_detection_row in unique_sirena_detections:                            \n",
    "                            i = sirena_detections_rows.index(uni_detection_row)\n",
    "                            irow_detection = sirena_detections_rows[i]\n",
    "                            if sirena_detections_rows.count(irow_detection) > 1: \n",
    "                                # get xifusim photons with the same sirena identification\n",
    "                                indices_mixed_photons = [j for j, x in enumerate(sirena_detections_rows) if x == irow_detection]  \n",
    "                                aux.vprint(f\"    SIRENA: Warning - indices_mixed_photons: {indices_mixed_photons}\")\n",
    "                                aux.vprint(f\"    SIRENA: Warning XIFUSIM photons with the same SIRENA row: {[xifusim_phs[j] for j in indices_mixed_photons]}\")\n",
    "                                # remove the closest xifusim photon to the sirena photon from the list of non-reconstructed photons\n",
    "                                photon_to_remove = PROBPHID[irow_detection]\n",
    "                                # get energy of the photon to remove (bad-recons) from piximpact file\n",
    "                                energy_badrecons = piximpactdata['ENERGY'][np.where(piximpactdata['PH_ID'] == photon_to_remove)][0]\n",
    "                                # and add the photon to the list of compromised photons\n",
    "                                aux.vprint(f\"    SIRENA: adding photon {photon_to_remove} to the list of compromised photons\")\n",
    "                                ph_bad_recons_inpix[ipixel] = np.append(ph_bad_recons_inpix[ipixel], int(photon_to_remove))                                \n",
    "                                # leave other mixed photons in the list of non-reconstructed photons\n",
    "                                missing_for_badrecons[photon_to_remove] = []\n",
    "                                energies_missing_for_badrecons[photon_to_remove] = []\n",
    "                                for j in range(len(indices_mixed_photons)):\n",
    "                                    photon_to_check = xifusim_phs[indices_mixed_photons[j]]\n",
    "                                    if photon_to_check != photon_to_remove:\n",
    "                                        aux.vprint(f\"    SIRENA: leaving photon {photon_to_check} in the list of non-reconstructed photons\")\n",
    "                                        # append photon_to_check to the list of missing photons for badrecons                                        \n",
    "                                        missing_for_badrecons[photon_to_remove].append(photon_to_check)\n",
    "                                        # append the energy of the photon to the list of energies\n",
    "                                        en_miss = piximpactdata['ENERGY'][np.where(piximpactdata['PH_ID'] == photon_to_check)]                            \n",
    "                                        energies_missing_for_badrecons[photon_to_remove].append(en_miss[0])\n",
    "                                message = (f\"Adding info to table:\"\n",
    "                                           f\" Pixel: {ipixel}, badrecons: {photon_to_remove}, energy_badrecons:{energy_badrecons}\"\n",
    "                                           f\" Missing phs: {missing_for_badrecons[photon_to_remove]}\"\n",
    "                                           f\" Energies_missing:{energies_missing_for_badrecons[photon_to_remove]}\"\n",
    "                                           f\" GRADE1_badrecons: {GRADE1[closest_sirena_row_for_photon[photon_to_remove]]}\"\n",
    "                                           f\" GRADE2_badrecons: {GRADE2[closest_sirena_row_for_photon[photon_to_remove]]}\")\n",
    "                                aux.vprint(message)\n",
    "                                # add info to the table\n",
    "                                info_table.loc[len(info_table)] = [ipixel, photon_to_remove, energy_badrecons,\n",
    "                                                                   missing_for_badrecons[photon_to_remove],\n",
    "                                                                   energies_missing_for_badrecons[photon_to_remove],\n",
    "                                                                   GRADE1[closest_sirena_row_for_photon[photon_to_remove]],\n",
    "                                                                   GRADE2[closest_sirena_row_for_photon[photon_to_remove]]]\n",
    "                            else: # only one photon in the list\n",
    "                                indices_mixed_photons = []\n",
    "                                photon_to_remove = xifusim_phs[i]\n",
    "                            # remove the photons found in the SIRENA file from the list of non-reconstructed photons\n",
    "                            aux.vprint(f\"    SIRENA: Removing photon {photon_to_remove} from the list of non-reconstructed photons\")\n",
    "                            ph_non_recons_inpix[ipixel] = np.delete(ph_non_recons_inpix[ipixel], np.where(ph_non_recons_inpix[ipixel] == photon_to_remove))\n",
    "\n",
    "                    elif len(indices_same_photons) > nphotons_in_sirena_record:\n",
    "                        aux.vprint(f\"    SIRENA: Warning: more detections ({len(indices_same_photons)}) than photons ({nphotons_in_sirena_record}) in the list {ph_full_sequence_sirena}\")                        \n",
    "                        nextra_recons_inpix[ipixel] += (len(indices_same_photons) - nphotons_in_sirena_record)\n",
    "                    else:\n",
    "                        # remove ph_full_sequence_sirena values from the list of non-reconstructed photons\n",
    "                        for ph in ph_full_sequence_sirena:\n",
    "                            aux.vprint(f\"    SIRENA: Removing photon {ph} from the list of non-reconstructed photons\")\n",
    "                            ph_non_recons_inpix[ipixel] = np.delete(ph_non_recons_inpix[ipixel], np.where(ph_non_recons_inpix[ipixel] == ph))\n",
    "                    # end comparison of nphotons in xifusim and nphotons in sirena\n",
    "                    \n",
    "                # end sirena row with more than 1 photon\n",
    "                # remove skipped photons in this pixel from the list of non-reconstructed photons\n",
    "                ph_non_recons_inpix[ipixel] = np.setdiff1d(ph_non_recons_inpix[ipixel], skipped_photons_inpix[ipixel])\n",
    "                \n",
    "            # end loop over rows in SIRENA file\n",
    "            nnon_recons_inpix[ipixel] = len(ph_non_recons_inpix[ipixel])\n",
    "            nbad_recons_inpix[ipixel] = len(ph_bad_recons_inpix[ipixel])\n",
    "        # end if pixel was skipped in xifusim (sirena file exists or not)\n",
    "        nbad_recons_total += nbad_recons_inpix[ipixel]\n",
    "        nrecons_total += nrecons_inpix[ipixel] - nextra_recons_inpix[ipixel] \n",
    "        nnon_recons_total += nnon_recons_inpix[ipixel]       \n",
    "        nimpacts_total += nimpacts_inpix[ipixel]\n",
    "    \n",
    "        if verbose > 0:\n",
    "            print(f\"Summary for Pixel {ipixel}: \")\n",
    "            print(f\"=====================================\")\n",
    "            print(f\"      {nimpacts_inpix[ipixel]} impacts\")\n",
    "            print(f\"      {nphsims_inpix[ipixel]} simulated photons\")\n",
    "            print(f\"      {nextra_recons_inpix[ipixel]} (extra)reconstructed photons\")\n",
    "            print(f\"      {nbad_recons_inpix[ipixel]} compromised-recons photons: {ph_bad_recons_inpix[ipixel]}\")\n",
    "            print(f\"      {nrecons_inpix[ipixel]} (final)reconstructed photons\")\n",
    "            print(f\"      {nnon_recons_inpix[ipixel]} missed photons: {ph_non_recons_inpix[ipixel]}\")\n",
    "            print(f\"      {nrecons_total} Accumulated reconstructed photons\")\n",
    "\n",
    "            # print missing photons in the pixel\n",
    "            if nrecons_inpix[ipixel] < nphsims_inpix[ipixel]:\n",
    "                # identify in which row of PH_ID_xifusim the missing photons are\n",
    "                hdulist = fits.open(f\"{filestring}_pixel{ipixel}_xifusim.fits\")\n",
    "                xifusimdata = hdulist[\"TESRECORDS\"].data\n",
    "                PH_ID_xifusim = xifusimdata['PH_ID']\n",
    "                hdulist.close()\n",
    "                idx_phs = []\n",
    "                for ph in ph_non_recons_inpix[ipixel]:\n",
    "                    idx_ph = np.where(PH_ID_xifusim == ph)[0]\n",
    "                    idx_phs.append(idx_ph)\n",
    "                    print(f\"      Missed photons: {ph} in xifusim rows {np.array(idx_ph)+1}\")\n",
    "\n",
    "    # end loop over pixels\n",
    "\n",
    "\n",
    "    # calculate fraction of lost photons: one is lost and the other one is piledup\n",
    "    #fraction_lost = 1. - nrecons_total/nimpacts_total \n",
    "    fraction_lost = nnon_recons_total/nimpacts_total\n",
    "    fraction_badrecons = nbad_recons_total/nimpacts_total\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95e6e1",
   "metadata": {},
   "source": [
    "## Save results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed information about missing photons for the simulation (for each pixel)\n",
    "if recons:\n",
    "    aux.vprint(info_table)\n",
    "    # save table to a csv file\n",
    "    infofile = f\"{outDir}/00_info_{filter}_{focus}_sim{sim_number}_missing.csv\"\n",
    "    info_table.to_csv(infofile, index=False)\n",
    "    aux.vprint(f\"Information saved to {infofile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a564c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if recons:\n",
    "    # simulation, flux_mcrab, exposure, filter, focus, number of pixels, number of impacts, number of reconstructed photons, fraction_lost\n",
    "    aux.vprint(f\"Simulation {sim_number}:\")\n",
    "    aux.vprint(f\"      Flux: {flux_mcrab:.3f} mCrab\")\n",
    "    aux.vprint(f\"      Exposure: {exposure:.2e} s\")\n",
    "    aux.vprint(f\"      Filter: {filter}\")\n",
    "    aux.vprint(f\"      Focus: {focus}\")\n",
    "    aux.vprint(f\"      Number of pixels: {len(pixels_with_impacts)}\")\n",
    "    aux.vprint(f\"      Number of impacts: {nimpacts_total}\")\n",
    "    aux.vprint(f\"      Number of reconstructed photons: {nrecons_total}\")\n",
    "    aux.vprint(f\"      Number of lost photons: {nnon_recons_total}\")\n",
    "    aux.vprint(f\"      Number of bad reconstructed photons: {nbad_recons_total}\")\n",
    "    aux.vprint(f\"      Fraction of lost photons: {fraction_lost:.2e}\")\n",
    "    aux.vprint(f\"      Fraction of bad reconstructed photons: {fraction_badrecons:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global info\n",
    "infofile = f\"info_{filter}_{focus}_global_{flux_mcrab:.3f}mCrab.csv\"\n",
    "if recons:\n",
    "    if not os.path.exists(infofile):\n",
    "        with open(infofile, 'w') as f:\n",
    "            f.write(f\"simulation,flux[mcrab],exposure[s],filter,focus,Npixels,Nimpacts,Nrecons,Missing,Nbadrecons,fraction_lost[%],fraction_badreconstructed[%]\\n\")\n",
    "    with open(infofile, 'a') as f:\n",
    "        f.write(f\"{sim_number},{flux_mcrab:.3f},{exposure:.2e},{filter},{focus},{len(pixels_with_impacts)},\"\n",
    "                f\"{nimpacts_total},{nrecons_total},{nnon_recons_total},{nbad_recons_total},\"\n",
    "                f\"{100*fraction_lost:.2e},{100*fraction_badrecons:.2e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ed7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSFCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
