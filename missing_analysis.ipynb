{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of missing pulses   \n",
    "\n",
    "For a given flux and exposure time this notebook analyzes the missing ('non-reconstructed') photons and plots the\n",
    "distribution of separations to their partner ('Bad-reconstructed' pulse).\n",
    "\n",
    "1. Import modules   \n",
    "2. Read parameters of simulation   \n",
    "3. Analysis of bad/non-reconstructed pulses   \n",
    "   * 3.1. Check distances between a missing photon and its corresponding \"bad-reconstructed\" photon:    \n",
    "        - For each simulation:   \n",
    "            * read CSV file with assignation of *missing* & *bad-reconstructed*   \n",
    "            * for each *missing* photon: get *bad-reconstructed* partner   \n",
    "                * read info in `piximpact` file   \n",
    "                * calculate minimum of the distances to all *bad-reconstructed*: this is its partner   \n",
    "                * save distance to global list of distances    \n",
    "                * Alert if:   \n",
    "                    * No *bad-reconstructed* photon is found for each *missing* photon: raise Error    \n",
    "                    * Separation [*missing*-*bad_renconstructed*] > 100: raise Error\n",
    "                    * Separation [*missing*-*bad_renconstructed*] > 30: warning to check particular cases    \n",
    "    * 3.2 Plot histograms of:   \n",
    "        - separations   \n",
    "        - energies:\n",
    "            - energies of missing photons   \n",
    "            - energies of badrecons photons   \n",
    "            - energies of impact photons   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(\"images/pileup.png\", width=350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "from astropy.visualization import hist\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import auxiliary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "global_csv_file = \"info_nofilt_infoc_global_0.500mCrab.csv\"\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims = 100\n",
    "sampling_rate=130210 #Hz\n",
    "secondary_samples = 1563\n",
    "close_dist_toxifusim = 100\n",
    "pileup_dist = 30\n",
    "auxiliary.verbose = verbose\n",
    "\n",
    "# get filter from file name\n",
    "filter = global_csv_file.split(\"_\")[1]\n",
    "# get focus from file name\n",
    "focus = global_csv_file.split(\"_\")[2]\n",
    "# get flux from file name\n",
    "flux_mcrab = float(global_csv_file.split(\"_\")[4].split(\"m\")[0])\n",
    "fluxDir = f\"{os.getcwd()}/flux{flux_mcrab:.2f}mcrab/\"\n",
    "print(f\"Filter: {filter}, Focus: {focus}, Flux: {flux_mcrab} mCrab\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of missing and bad-reconstructed photons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pile-up photons separations \n",
    "\n",
    "Check distances between a missing photon and its corresponding \"bad-reconstructed\" photon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_distances = list()\n",
    "missing_energies  = list()\n",
    "badrecons_energies = list()\n",
    "miss0_energies = list() # energies of the first missing photon\n",
    "badrecons_energies_secondaries = list()\n",
    "badrecons_energies_lowres = list()\n",
    "badrecons_energies_primaries = list()\n",
    "Ntimes_couples_far = 0\n",
    "\n",
    "for i in range(nsims):\n",
    "    isim = i + 1\n",
    "    #if not isim == 1:\n",
    "    #    continue\n",
    "    csv_file = f\"{fluxDir}/sim_{isim}/00_info_{filter}_{focus}_sim{isim}_missing.csv\"\n",
    "    missing_table = pd.read_csv(csv_file, converters={\"Bad-reconstructed photons\": ast.literal_eval,\n",
    "                                                    \"Non-reconstructed photons\": ast.literal_eval,\n",
    "                                                    \"GRADE1 Bad-recons\": ast.literal_eval,\n",
    "                                                    \"GRADE2 Bad-recons\": ast.literal_eval})\n",
    "    \n",
    "    #read table row by row:\n",
    "    # First column is an integer value that represents the pixel id\n",
    "    # Second column are integers that represents the PH_ID of the badrecons photons\n",
    "    # Third column is a list of integers that represents the PH_ID of the missing photons for each reconstructed photon\n",
    "    # Fourth column is a list of integers that represents the GRADE1 of the badrecons photons\n",
    "    # Fifth column is a list of integers that represents the GRADE2 of the badrecons photons\n",
    "\n",
    "    # read table rows grouped by pixel\n",
    "    pixels_in_table = missing_table[\"Pixel\"].unique()\n",
    "    for ipixel in pixels_in_table:\n",
    "        rows_with_same_pixel = missing_table[missing_table[\"Pixel\"] == ipixel]\n",
    "        # identify sirena file\n",
    "        sirena_files = glob.glob(f\"{fluxDir}/sim_{isim}/crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp*_RA0.0_Dec0.0_{filter}_{focus}_pixel{ipixel}_sirena.fits\")\n",
    "        if len(sirena_files) == 0:\n",
    "            print(f\"sim {isim}, pixel {ipixel}: no sirena file found\")\n",
    "            raise ValueError(\"No sirena file found\")\n",
    "        if len(sirena_files) > 1:\n",
    "            print(f\"sim {isim}, pixel {ipixel}: more than one sirena file found\")\n",
    "            raise ValueError(\"More than one sirena file found\")\n",
    "        sirena_file = sirena_files[0]\n",
    "        # remove path from the file name\n",
    "        sirena_file_nopath = sirena_file.split(\"/\")[-1]\n",
    "        # get exposure from the file name\n",
    "        exposure = sirena_file_nopath.split(\"_\")[4].split(\"exp\")[1]\n",
    "        # identify piximpact file for pixel\n",
    "        piximpact_file = f\"{fluxDir}/sim_{isim}/crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp{exposure}_RA0.0_Dec0.0_{filter}_{focus}_pixel{ipixel}_piximpact.fits\"\n",
    "        # read TIME and PH_ID columns of piximpact FITS file\n",
    "        with fits.open(piximpact_file) as hdul:\n",
    "            piximpact_data = hdul[1].data\n",
    "            time_piximpact = piximpact_data[\"TIME\"].copy()\n",
    "            ph_id = piximpact_data[\"PH_ID\"].copy()\n",
    "            simenergy = piximpact_data[\"ENERGY\"].copy()\n",
    "\n",
    "        #for i, row in missing_table.iterrows():\n",
    "        for irow, row in rows_with_same_pixel.iterrows():\n",
    "            all_missing_phs_id = row[\"Non-reconstructed photons\"]\n",
    "            all_missing_phs_id = row[\"Non-reconstructed photons\"]\n",
    "            bad_recons_ph_id = row[\"Bad-reconstructed photons\"]\n",
    "            bad_recons_grade1 = row[\"GRADE1 Bad-recons\"]\n",
    "            bad_recons_grade2 = row[\"GRADE2 Bad-recons\"]\n",
    "            auxiliary.vprint(f\"sim {isim}, pixel {ipixel}, missing photons {all_missing_phs_id}, bad reconstructed photons {bad_recons_ph_id}\")\n",
    "\n",
    "            # foreach missing photon, find the TIME distance to its 'partner'-bad-reconstructed photon\n",
    "            for imissing in all_missing_phs_id:\n",
    "                missing_time = time_piximpact[ph_id == imissing][0] \n",
    "                bad_time = time_piximpact[ph_id == bad_recons_ph_id][0]\n",
    "                time_diff_samples = np.abs(missing_time - bad_time)*sampling_rate\n",
    "                if time_diff_samples > close_dist_toxifusim:\n",
    "                    # this should never happen, as only couples separated by less than close_dist_toxifusim are simulated\n",
    "                    message = f\"sim {isim}, pixel {ipixel}: missing ph {imissing} and bad ph {bad_recons_ph_id} are separated by {time_diff_samples:.2f} samples\"\n",
    "                    print(message)\n",
    "                    raise ValueError(message)\n",
    "                if time_diff_samples > pileup_dist:\n",
    "                    message = f\"Sim {isim}, pixel{ipixel}:Time difference between missing and bad reconstructed photons is too large:{time_diff_samples:.2f} samples\"\n",
    "                    print(message)\n",
    "                    Ntimes_couples_far += 1\n",
    "                # append the minimum time difference to the list of missing distances\n",
    "                missing_distances.append(time_diff_samples)\n",
    "                missing_energies.append(simenergy[ph_id == imissing][0])\n",
    "                auxiliary.vprint(f\"sim {isim}, pixel {ipixel}, missing ph {imissing}, bad ph {bad_recons_ph_id}, min time diff {time_diff_samples:.2f}\")\n",
    "            imissing0 = all_missing_phs_id[0]\n",
    "            \n",
    "            # check bad-recons photons\n",
    "            badr_energy = simenergy[ph_id == bad_recons_ph_id][0]\n",
    "            badr_grade1 = bad_recons_grade1\n",
    "            badr_grade2 = bad_recons_grade2\n",
    "            if badr_grade2 <= secondary_samples:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {bad_recons_ph_id}, grade1 {badr_grade1}, grade2 {badr_grade2}: SECONDARY\")\n",
    "                badrecons_energies_secondaries.append(badr_energy)\n",
    "            elif badr_grade1 == 8:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {bad_recons_ph_id}, grade1 {badr_grade1}, grade2 {badr_grade2}: LOWRES\")\n",
    "                badrecons_energies_lowres.append(badr_energy)\n",
    "            else:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {bad_recons_ph_id}, grade1 {badr_grade1}, grade2 {badr_grade2}: PRIMARY\")\n",
    "                badrecons_energies_primaries.append(badr_energy)\n",
    "            badrecons_energies.append(badr_energy)\n",
    "            miss0_energies.append(simenergy[ph_id == imissing0][0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Ntimes_couples_far > 0:\n",
    "    print(f\"Number of times couples far: {Ntimes_couples_far}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of pileup separations and energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read global CSV table with info of all simulations\n",
    "# look for \"Nimpacts\" column info selecting where the 'flux[mcrab]' matches the flux of the simulations\n",
    "global_table = pd.read_csv(global_csv_file)\n",
    "global_table = global_table[global_table[\"flux[mcrab]\"] == float(flux_mcrab)]\n",
    "global_table = global_table[global_table[\"filter\"] == filter]\n",
    "# get total number of impacts (for all 'simulation')\n",
    "print(\"Data from table:\")\n",
    "Nimpacts = global_table[\"Nimpacts\"].sum()\n",
    "print(f\"   Total number of impacts: {Nimpacts}\")\n",
    "Nmissing = len(missing_distances)\n",
    "print(f\"   Total number of missing impacts: {Nmissing}\")\n",
    "Nbadrecons = len(badrecons_energies)\n",
    "print(f\"   Total number of bad reconstructed impacts: {Nbadrecons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total distribution of photons from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ** ARF/RMF threshold = 0.15keV but X-IFU/XML readout threshold=0.2keV **\n",
    "# a) photons in impact list with 0.15keV<E<=0.2keV are not reconstructed by sixtesim (ENERGY assigned in EVT list is 0 keV)\n",
    "# b) if obtained from the impact list they will have the correct energy:\n",
    "#       -> simulated by xifusim but pulses will be probably undetectable (?)    \n",
    "# c) if not in the initial impact list (BGD photons):\n",
    "#       -> they are not simulated by xifusim and will have 0 energy  \n",
    "#       \n",
    "impact_energies = list()\n",
    "Nlow_total = 0\n",
    "Nevt_total = 0\n",
    "Nimp_total = 0\n",
    "evt_file = f\"crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp{exposure}_RA0.0_Dec0.0_{filter}_{focus}_evt.fits\"\n",
    "imp_file = f\"crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp{exposure}_RA0.0_Dec0.0_{filter}_{focus}_impact.fits\"\n",
    "\n",
    "for isim in range(1,nsims+1):\n",
    "    evt_file_sim = f\"{fluxDir}/sim_{isim}/{evt_file}\"\n",
    "    imp_file_sim = f\"{fluxDir}/sim_{isim}/{imp_file}\"\n",
    "    print(f\"Saving energy of photons in impact list for sim {isim}...\")\n",
    "    # read PH_ID from evt_file and ENERGY from impact list\n",
    "    with fits.open(evt_file_sim) as hdul:\n",
    "        evt_data = hdul[1].data\n",
    "        evt_ph_id = evt_data[\"PH_ID\"].copy()\n",
    "        evt_energy = evt_data[\"SIGNAL\"].copy()\n",
    "    with fits.open(imp_file_sim) as hdul:\n",
    "        imp_data = hdul[1].data\n",
    "        imp_ph_id = imp_data[\"PH_ID\"].copy()\n",
    "        imp_energy = imp_data[\"ENERGY\"].copy()\n",
    "    # get the ENERGY of the photons in the impact list whose PH_ID is in the evt list\n",
    "    impact_energies_sim = imp_energy[np.isin(imp_ph_id, evt_ph_id)]\n",
    "    print(f\"           Number of photons in impact list: {len(imp_ph_id)}\")\n",
    "    print(f\"           Number of photons in evt list: {len(evt_ph_id)}\")\n",
    "    Nimp_total += len(imp_ph_id)\n",
    "    Nevt_total += len(evt_ph_id)\n",
    "    # add energies to the list\n",
    "    impact_energies.extend(impact_energies_sim)\n",
    "    # add the energies of the BGD photons in the evt list: PH_ID < 0\n",
    "    # they are not in the global impact list (but they are added to the pixel impact list and thus they are simulated)\n",
    "    bgd_ph_id = evt_ph_id[evt_ph_id < 0]\n",
    "    bgd_ph_energy = evt_energy[evt_ph_id < 0]\n",
    "    # add the energies to the list\n",
    "    impact_energies.extend(bgd_ph_energy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary\n",
    "Nlow_total = len([energy for energy in impact_energies if (energy < 0.2 and energy >0.)])\n",
    "Nbgd_total = len([energy for energy in impact_energies if (energy == 0)])\n",
    "print(f\"Total number of impacts (table): {Nimpacts}\")\n",
    "print(f\"Total number of impact energies: {len(impact_energies)}\")\n",
    "print(f\"Total number of event energies: {Nevt_total}\")\n",
    "print(f\"Total number of total impacts (pre-sixtesim): {Nimp_total}\")\n",
    "print(f\"Total number of missing impacts: {Nmissing}\")\n",
    "print(f\"Total number of bad reconstructed impacts: {Nbadrecons}\")\n",
    "nbadprim = len(badrecons_energies_primaries)\n",
    "nbadsec = len(badrecons_energies_secondaries)\n",
    "nbadlowres = len(badrecons_energies_lowres) \n",
    "print(f\"Number of bad reconstructed photons (primary): {nbadprim}\")\n",
    "print(f\"Number of bad reconstructed photons (secondary): {nbadsec}\")\n",
    "print(f\"Number of bad reconstructed photons (low-res): {nbadlowres}\")\n",
    "print(f\"Number of events with energy < 0.2 keV: {Nlow_total}\")\n",
    "print(f\"BGD events with 0 energy: {Nbgd_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of distribution of missing photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with two plots\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,6))\n",
    "# In ax1: plot histogram of distances (in samples) for missing photons\n",
    "# =====================================================================\n",
    "#ax1.hist(missing_distances, bins=50, edgecolor='black')\n",
    "hist(missing_distances, bins='scott', ax=ax1, edgecolor='black')\n",
    "ax1.set_xlabel(\"Time difference (samples)\")\n",
    "ax1.set_ylabel(\"# missing photons\")\n",
    "ax1.set_title(\"Time separations of missing photons\")\n",
    "# write text on the plot: number of simulations, flux, exposure, sampling rate\n",
    "text = (f\"nsims = {nsims}\\n\"\n",
    "        f\"Nimpacts = {Nimpacts}\\n\"\n",
    "        f\"Nmissing = {Nmissing}\\n\"\n",
    "        f\"Nbadrecons = {Nbadrecons}\\n\"\n",
    "        f\"flux = {flux_mcrab} mCrab\\n\"\n",
    "        f\"Filter = {filter}\\n\"\n",
    "        f\"Focus = {focus}\\n\"\n",
    "        f\"N(E<0.2keV)={Nlow_total}\\n\"\n",
    "        f\"sampling rate = {sampling_rate} Hz\\n\"\n",
    "        f\"Ncouples(>{pileup_dist}sam) = {Ntimes_couples_far}\\n\") \n",
    "\n",
    "ax1.text(0.5, 0.95, text, transform=ax1.transAxes, fontsize=10, verticalalignment='top')\n",
    "\n",
    "# In ax2: plot histogram of energies of impact photons, missing photons and bad-reconstructed photons\n",
    "# =====================================================================\n",
    "Ncts_bin, miss_bins, handle_miss = hist(missing_energies,ax=ax2, alpha=0.8, bins='scott',histtype='step',label=[\"missing photons\"], color='C0', log=True)\n",
    "bin_size = miss_bins[1] - miss_bins[0]\n",
    "_, _, handle_bad = hist(badrecons_energies,ax=ax2,alpha=0.8, bins=miss_bins,histtype='step',label=[\"bad-recons photons\\n(prim+second+low-res)\"], color='C1',log=True)\n",
    "\n",
    "if len(badrecons_energies_primaries) > 0:\n",
    "    _, _, handle_prim = hist(badrecons_energies_primaries,ax=ax2,alpha=0.5, bins=miss_bins,histtype='step',label=[f\"bad-recons photons\\n(primary):{nbadprim}\"],color='C2', log=True)\n",
    "if len(badrecons_energies_secondaries) > 0:\n",
    "    _, _, handle_sec = hist(badrecons_energies_secondaries,ax=ax2,alpha=0.5, bins=miss_bins,label=[f\"bad-recons photons\\n(secondary):{nbadsec}\"], color='C3',log=True)\n",
    "if len(badrecons_energies_lowres) > 0:\n",
    "    _, _, handle_low = hist(badrecons_energies_lowres,ax=ax2,alpha=0.5, bins=miss_bins,label=[f\"bad-recons photons\\n(low-res):{nbadlowres}\"], color='C4',log=True)\n",
    "# add evt photon energy distribution to histogram\n",
    "_, _, handle_all = hist(impact_energies,ax=ax2,alpha=0.3, bins=miss_bins,label=[\"impact photons\"], color='C8',log=True)\n",
    "# plot a vertical line at 0.2 keV\n",
    "handle_xifu = ax2.axvline(x=0.2, color='r', linestyle='--', alpha=0.5, label=\"X-IFU threshold\")\n",
    "\n",
    "# add re-scaled \"handle_all\" histogram to see if it keeps the same shape than the missing histogram\n",
    "all_np_hist, _ = np.histogram(impact_energies, bins=miss_bins)\n",
    "scaling_factor = Ncts_bin.sum() / all_np_hist.sum() # miss/all\n",
    "rescaled_all = all_np_hist * scaling_factor\n",
    "# Plot the rescaled histogram\n",
    "handle_re = ax2.step(miss_bins[:-1], rescaled_all, where='mid', linestyle=':', color='black', \n",
    "         label=\"impact photons (rescaled)\", alpha=0.8)\n",
    "\n",
    "# add legend in an specific order\n",
    "handles = [handle_all[0], handle_miss[0], handle_bad[0], handle_prim[0], handle_sec[0], handle_low[0], handle_re[0],handle_xifu]\n",
    "labels = [h.get_label() for h in handles]\n",
    "ax2.legend(handles, labels, loc='upper right', fontsize=8, frameon=False)\n",
    "\n",
    "ax2.set_xlabel(\"Energy (keV)\")\n",
    "ax2.set_ylabel(f\"# photons/{bin_size:.2f}keV\")\n",
    "ax2.set_title(\"Photon energy distribution\")\n",
    "plt.show()\n",
    "# save image to PDF file\n",
    "fig.savefig(f\"./Figures/missing_{filter}_{focus}_{flux_mcrab:.2f}mCrab.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary.vprint(f\"Missing energies: {miss0_energies}\")\n",
    "auxiliary.vprint(f\"Bad-recons energies: {badrecons_energies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image of combinations of energies of the bad-recons and their corresponding missing partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2D map\n",
    "# X axis: energies of bad-reconstructed photons\n",
    "# Y axis: energies of missing photons (first of them if there are more than one for the same bad-reconstructed photon)\n",
    "# =====================================================================\n",
    "# create a 2D histogram\n",
    "histo_miss_bad = np.histogram2d(miss0_energies, badrecons_energies, bins=[np.linspace(0, 10, 100), np.linspace(0, 10, 100)])\n",
    "# create a figure\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(14, 6))\n",
    "# add title\n",
    "fig.suptitle(f\"Missing vs Bad-reconstructed photons: {flux_mcrab} mCrab, {filter}, {focus}\")\n",
    "# plot the histogram as an image\n",
    "im = ax1.imshow(histo_miss_bad[0], cmap='hot', interpolation='nearest', origin='lower', extent=[0, 10, 0, 10])\n",
    "# label x as \"Missing photon energy (keV)\"\n",
    "ax1.set_xlabel(\" (1st) Missing photon energy (keV)\")\n",
    "# label y as \"Bad-reconstructed photon energy (keV)\"\n",
    "ax1.set_ylabel(\"Bad-reconstructed photon energy (keV)\")\n",
    "# add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax1)\n",
    "cbar.set_label(\"# photons\")\n",
    "\n",
    "# plot the histogram as a contour plot\n",
    "contour = ax2.contour(histo_miss_bad[0], levels=10, cmap='hot', extent=[0, 10, 0, 10])\n",
    "# label x as \"Missing photon energy (keV)\"\n",
    "ax2.set_xlabel(\" (1st) Missing photon energy (keV)\")\n",
    "# label y as \"Bad-reconstructed photon energy (keV)\"\n",
    "ax2.set_ylabel(\"Bad-reconstructed photon energy (keV)\")\n",
    "# add colorbar\n",
    "cbar = plt.colorbar(contour, ax=ax2)\n",
    "cbar.set_label(\"# photons\")\n",
    "# save image to PDF file\n",
    "fig.savefig(f\"./Figures/missing_vs_badrecons_{filter}_{focus}_{flux_mcrab:.2f}mCrab.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSFCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
