{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of missing pulses   \n",
    "\n",
    "For a given flux and exposure time this notebook analyzes the missing ('non-reconstructed') photons and plots the\n",
    "distribution of separations to their partner ('Bad-reconstructed' pulse).\n",
    "\n",
    "1. Import modules   \n",
    "2. Read parameters of simulation   \n",
    "3. Analysis of bad/non-reconstructed pulses   \n",
    "   * 3.1. Check distances between a missing photon and its corresponding \"bad-reconstructed\" photon:    \n",
    "        - For each simulation:   \n",
    "            * read CSV file with assignation of *missing* & *bad-reconstructed*   \n",
    "            * for each *missing* photon: get *bad-reconstructed* partner   \n",
    "                * read info in `piximpact` file   \n",
    "                * calculate minimum of the distances to all *bad-reconstructed*: this is its partner   \n",
    "                * save distance to global list of distances    \n",
    "                * Alert if:   \n",
    "                    * No *bad-reconstructed* photon is found for each *missing* photon: raise Error    \n",
    "                    * Separation [*missing*-*bad_renconstructed*] > 100: raise Error\n",
    "                    * Separation [*missing*-*bad_renconstructed*] > 30: warning to check particular cases    \n",
    "    * 3.2 Plot histograms of:   \n",
    "        - separations   \n",
    "        - energies:\n",
    "            - energies of missing photons   \n",
    "            - energies of badrecons photons   \n",
    "            - energies of impact photons   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(\"images/pileup.png\", width=350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "from astropy.visualization import hist\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import auxiliary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "global_csv_file = \"info_nofilt_defoc_global_316.200mCrab.csv\"\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims = 100\n",
    "sampling_rate=130210 #Hz\n",
    "secondary_samples = 1563\n",
    "close_dist_toxifusim = 100\n",
    "pileup_dist = 30\n",
    "auxiliary.verbose = verbose\n",
    "\n",
    "# get filter from file name\n",
    "filter = global_csv_file.split(\"_\")[1]\n",
    "# get focus from file name\n",
    "focus = global_csv_file.split(\"_\")[2]\n",
    "# get flux from file name\n",
    "flux_mcrab = float(global_csv_file.split(\"_\")[4].split(\"m\")[0])\n",
    "fluxDir = f\"{os.getcwd()}/flux{flux_mcrab:.2f}mcrab/\"\n",
    "print(f\"Filter: {filter}, Focus: {focus}, Flux: {flux_mcrab} mCrab\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of missing and bad-reconstructed photons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pile-up photons separations \n",
    "\n",
    "Check distances between a missing photon and its corresponding \"bad-reconstructed\" photon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_distances = list()\n",
    "missing_energies  = list()\n",
    "badrecons_energies = list()\n",
    "badrecons_energies_secondaries = list()\n",
    "badrecons_energies_lowres = list()\n",
    "badrecons_energies_primaries = list()\n",
    "Ntimes_couples_far = 0\n",
    "\n",
    "for i in range(nsims):\n",
    "    isim = i + 1\n",
    "    #if not isim == 1:\n",
    "    #    continue\n",
    "    csv_file = f\"{fluxDir}/sim_{isim}/00_info_{filter}_{focus}_sim{isim}_missing.csv\"\n",
    "    missing_table = pd.read_csv(csv_file, converters={\"Non-reconstructed photons\": ast.literal_eval,\n",
    "                                                      \"Bad-reconstructed photons\": ast.literal_eval,\n",
    "                                                      \"GRADE1 Bad-recons\": ast.literal_eval,\n",
    "                                                      \"GRADE2 Bad-recons\": ast.literal_eval})\n",
    "    \n",
    "    #read table row by row:\n",
    "    # First column is an integer value that represents the pixel id\n",
    "    # Second column is a list of integers that represents the PH_ID of the missing photons\n",
    "    # Third column is a list of integers that represents the PH_ID of the photons that are bad reconstructed    \n",
    "    for i, row in missing_table.iterrows():\n",
    "        ipixel = row[\"Pixel\"]\n",
    "        missing_phs_id = row[\"Non-reconstructed photons\"]\n",
    "        bad_recons_phs_id = row[\"Bad-reconstructed photons\"]\n",
    "        bad_recons_grade1 = row[\"GRADE1 Bad-recons\"]\n",
    "        bad_recons_grade2 = row[\"GRADE2 Bad-recons\"]\n",
    "        auxiliary.vprint(f\"sim {isim}, pixel {ipixel}, missing photons {missing_phs_id}, bad reconstructed photons {bad_recons_phs_id}\")\n",
    "        # identify sirena file\n",
    "        sirena_file = glob.glob(f\"{fluxDir}/sim_{isim}/crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp*_RA0.0_Dec0.0_{filter}_{focus}_pixel{ipixel}_sirena.fits\")\n",
    "        if len(sirena_file) == 0:\n",
    "            print(f\"sim {isim}, pixel {ipixel}: no sirena file found\")\n",
    "            raise ValueError(\"No sirena file found\")\n",
    "        # remove path from the file name\n",
    "        sirena_file_nopath = sirena_file[0].split(\"/\")[-1]\n",
    "        # get exposure from the file name\n",
    "        exposure = sirena_file_nopath.split(\"_\")[4].split(\"exp\")[1]\n",
    "        sirena_file = f\"{fluxDir}/sim_{isim}/crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp{exposure}_RA0.0_Dec0.0_{filter}_{focus}_pixel{ipixel}_sirena.fits\"\n",
    "        # identify piximpact file for pixel\n",
    "        piximpact_file = f\"{fluxDir}/sim_{isim}/crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp{exposure}_RA0.0_Dec0.0_{filter}_{focus}_pixel{ipixel}_piximpact.fits\"\n",
    "        # read TIME and PH_ID columns of piximpact FITS file\n",
    "        with fits.open(piximpact_file) as hdul:\n",
    "            piximpact_data = hdul[1].data\n",
    "            time = piximpact_data[\"TIME\"].copy()\n",
    "            ph_id = piximpact_data[\"PH_ID\"].copy()\n",
    "            simenergy = piximpact_data[\"ENERGY\"].copy()\n",
    "\n",
    "        # foreach missing photon, find the minimum TIME distance to the bad reconstructed photons (find its 'partner')\n",
    "        for imissing in missing_phs_id:\n",
    "            missing_time = time[ph_id == imissing][0] \n",
    "            min_time_diff_samples = float(\"inf\")   \n",
    "            # find the bad reconstructed photon that is closest in time to the missing photon\n",
    "            min_bad = None\n",
    "            for ibad in bad_recons_phs_id:\n",
    "                bad_time = time[ph_id == ibad][0]\n",
    "                time_diff_samples = np.abs(missing_time - bad_time)*sampling_rate\n",
    "                if time_diff_samples < min_time_diff_samples:\n",
    "                    min_time_diff_samples = time_diff_samples\n",
    "                    min_bad = ibad\n",
    "            if min_bad is None:\n",
    "                message = f\"sim {isim}, pixel {ipixel}: missing ph {imissing} has no bad ph\"\n",
    "                print(f\"{message}\")\n",
    "                raise ValueError(f\"{message}\")\n",
    "            if min_time_diff_samples > close_dist_toxifusim:\n",
    "                message = f\"sim {isim}, pixel {ipixel}: missing ph {imissing} and bad ph {min_bad} are separated by {min_time_diff_samples:.2f} samples\"\n",
    "                print(message)\n",
    "                raise ValueError(message)\n",
    "            if min_time_diff_samples > pileup_dist:\n",
    "                message = f\"Sim {isim}, pixel{ipixel}:Time difference between missing and bad reconstructed photons is too large:{min_time_diff_samples:.2f} samples\"\n",
    "                print(message)\n",
    "                Ntimes_couples_far += 1\n",
    "    \n",
    "            # append the minimum time difference to the list of missing distances\n",
    "            missing_distances.append(min_time_diff_samples)\n",
    "            missing_energies.append(simenergy[ph_id == imissing][0])\n",
    "            auxiliary.vprint(f\"sim {isim}, pixel {ipixel}, missing ph {imissing}, bad ph {min_bad}, min time diff {min_time_diff_samples:.2f}\")\n",
    "        \n",
    "        # check bad-recons photons\n",
    "        for ib in range(len(bad_recons_phs_id)):\n",
    "            badr = bad_recons_phs_id[ib]\n",
    "            badr_energy = simenergy[ph_id == badr][0]\n",
    "            badr_grade1 = bad_recons_grade1[ib] \n",
    "            badr_grade2 = bad_recons_grade2[ib]\n",
    "            if badr_grade2 <= secondary_samples:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {badr}, grade1 {badr_grade1}, grade2 {badr_grade2}: SECONDARY\")\n",
    "                badrecons_energies_secondaries.append(badr_energy)\n",
    "            elif badr_grade1 == 8:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {badr}, grade1 {badr_grade1}, grade2 {badr_grade2}: LOWRES\")\n",
    "                badrecons_energies_lowres.append(badr_energy)\n",
    "            else:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {badr}, grade1 {badr_grade1}, grade2 {badr_grade2}: PRIMARY\")\n",
    "                badrecons_energies_primaries.append(badr_energy)\n",
    "            badrecons_energies.append(badr_energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Ntimes_couples_far > 0:\n",
    "    print(f\"Number of times couples far: {Ntimes_couples_far}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of pileup separations and energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read global CSV table with info of all simulations\n",
    "# look for \"Nimpacts\" column info selecting where the 'flux[mcrab]' matches the flux of the simulations\n",
    "global_table = pd.read_csv(global_csv_file)\n",
    "global_table = global_table[global_table[\"flux[mcrab]\"] == float(flux_mcrab)]\n",
    "global_table = global_table[global_table[\"filter\"] == filter]\n",
    "# get total number of impacts (for all 'simulation')\n",
    "print(\"Data from table:\")\n",
    "Nimpacts = global_table[\"Nimpacts\"].sum()\n",
    "print(f\"   Total number of impacts: {Nimpacts}\")\n",
    "Nmissing = len(missing_distances)\n",
    "print(f\"   Total number of missing impacts: {Nmissing}\")\n",
    "Nbadrecons = len(badrecons_energies)\n",
    "print(f\"   Total number of bad reconstructed impacts: {Nbadrecons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total distribution of photons from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ** ARF/RMF threshold = 0.15keV but X-IFU/XML readout threshold=0.2keV **\n",
    "# a) photons in impact list with 0.15keV<E<=0.2keV are not reconstructed by sixtesim (ENERGY assigned in EVT list is 0 keV)\n",
    "# b) if obtained from the impact list they will have the correct energy:\n",
    "#       -> simulated by xifusim but pulses will be probably undetectable (?)    \n",
    "# c) if not in the initial impact list (BGD photons):\n",
    "#       -> they are not simulated by xifusim and will have 0 energy  \n",
    "#       \n",
    "impact_energies = list()\n",
    "Nlow_total = 0\n",
    "Nevt_total = 0\n",
    "Nimp_total = 0\n",
    "evt_file = f\"crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp{exposure}_RA0.0_Dec0.0_{filter}_{focus}_evt.fits\"\n",
    "imp_file = f\"crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp{exposure}_RA0.0_Dec0.0_{filter}_{focus}_impact.fits\"\n",
    "\n",
    "for isim in range(1,nsims+1):\n",
    "    evt_file_sim = f\"{fluxDir}/sim_{isim}/{evt_file}\"\n",
    "    imp_file_sim = f\"{fluxDir}/sim_{isim}/{imp_file}\"\n",
    "    print(f\"Saving energy of photons in impact list for sim {isim}...\")\n",
    "    # read PH_ID from evt_file and ENERGY from impact list\n",
    "    with fits.open(evt_file_sim) as hdul:\n",
    "        evt_data = hdul[1].data\n",
    "        evt_ph_id = evt_data[\"PH_ID\"].copy()\n",
    "        evt_energy = evt_data[\"SIGNAL\"].copy()\n",
    "    with fits.open(imp_file_sim) as hdul:\n",
    "        imp_data = hdul[1].data\n",
    "        imp_ph_id = imp_data[\"PH_ID\"].copy()\n",
    "        imp_energy = imp_data[\"ENERGY\"].copy()\n",
    "    # get the ENERGY of the photons in the impact list whose PH_ID is in the evt list\n",
    "    impact_energies_sim = imp_energy[np.isin(imp_ph_id, evt_ph_id)]\n",
    "    print(f\"           Number of photons in impact list: {len(imp_ph_id)}\")\n",
    "    print(f\"           Number of photons in evt list: {len(evt_ph_id)}\")\n",
    "    Nimp_total += len(imp_ph_id)\n",
    "    Nevt_total += len(evt_ph_id)\n",
    "    # add energies to the list\n",
    "    impact_energies.extend(impact_energies_sim)\n",
    "    # add the energies of the BGD photons in the evt list: PH_ID < 0\n",
    "    # they are not in the global impact list (but they are in the pixel impact list and thus they are simulated)\n",
    "    bgd_ph_id = evt_ph_id[evt_ph_id < 0]\n",
    "    bgd_ph_energy = evt_energy[evt_ph_id < 0]\n",
    "    # add the energies to the list\n",
    "    impact_energies.extend(bgd_ph_energy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary\n",
    "Nlow_total = len([energy for energy in impact_energies if (energy < 0.2 and energy >0.)])\n",
    "Nbgd_total = len([energy for energy in impact_energies if (energy == 0)])\n",
    "print(f\"Total number of impacts (table): {Nimpacts}\")\n",
    "print(f\"Total number of impact energies: {len(impact_energies)}\")\n",
    "print(f\"Total number of event energies: {Nevt_total}\")\n",
    "print(f\"Total number of total impacts (pre-sixtesim): {Nimp_total}\")\n",
    "print(f\"Total number of missing impacts: {Nmissing}\")\n",
    "print(f\"Total number of bad reconstructed impacts: {Nbadrecons}\")\n",
    "nbadprim = len(badrecons_energies_primaries)\n",
    "nbadsec = len(badrecons_energies_secondaries)\n",
    "nbadlowres = len(badrecons_energies_lowres) \n",
    "print(f\"Number of bad reconstructed photons (primary): {nbadprim}\")\n",
    "print(f\"Number of bad reconstructed photons (secondary): {nbadsec}\")\n",
    "print(f\"Number of bad reconstructed photons (low-res): {nbadlowres}\")\n",
    "print(f\"Number of events with energy < 0.2 keV: {Nlow_total}\")\n",
    "print(f\"BGD events with 0 energy: {Nbgd_total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with two plots\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,6))\n",
    "# In ax1: plot histogram of distances (in samples) for missing photons\n",
    "# =====================================================================\n",
    "#ax1.hist(missing_distances, bins=50, edgecolor='black')\n",
    "hist(missing_distances, bins='scott', ax=ax1, edgecolor='black')\n",
    "ax1.set_xlabel(\"Time difference (samples)\")\n",
    "ax1.set_ylabel(\"# missing photons\")\n",
    "ax1.set_title(\"Time separations of missing photons\")\n",
    "# write text on the plot: number of simulations, flux, exposure, sampling rate\n",
    "text = (f\"nsims = {nsims}\\n\"\n",
    "        f\"Nimpacts = {Nimpacts}\\n\"\n",
    "        f\"Nmissing = {Nmissing}\\n\"\n",
    "        f\"Nbadrecons = {Nbadrecons}\\n\"\n",
    "        f\"flux = {flux_mcrab} mCrab\\n\"\n",
    "        f\"Filter = {filter}\\n\"\n",
    "        f\"Focus = {focus}\\n\"\n",
    "        f\"N(E<0.2keV)={Nlow_total}\\n\"\n",
    "        f\"sampling rate = {sampling_rate} Hz\\n\"\n",
    "        f\"Ncouples(>{pileup_dist}sam) = {Ntimes_couples_far}\\n\") \n",
    "\n",
    "ax1.text(0.5, 0.95, text, transform=ax1.transAxes, fontsize=10, verticalalignment='top')\n",
    "\n",
    "# In ax2: plot histogram of energies of impact photons, missing photons and bad-reconstructed photons\n",
    "# =====================================================================\n",
    "hist(missing_energies,ax=ax2, alpha=0.8, bins='scott',histtype='step',label=[\"missing photons\"], color='C0', log=True)\n",
    "hist(badrecons_energies,ax=ax2,alpha=0.8, bins='scott',histtype='step',label=[\"bad-recons photons\\n(prim+second+low-res)\"], color='C1',log=True)\n",
    "if len(badrecons_energies_primaries) > 0:\n",
    "    hist(badrecons_energies_primaries,ax=ax2,alpha=0.5, bins='scott',histtype='step',label=[f\"bad-recons photons\\n(primary):{nbadprim}\"],color='C2', log=True)\n",
    "if len(badrecons_energies_secondaries) > 0:\n",
    "    hist(badrecons_energies_secondaries,ax=ax2,alpha=0.5, bins='scott',label=[f\"bad-recons photons\\n(secondary):{nbadsec}\"], color='C3',log=True)\n",
    "if len(badrecons_energies_lowres) > 0:\n",
    "    hist(badrecons_energies_lowres,ax=ax2,alpha=0.5, bins='scott',label=[f\"bad-recons photons\\n(low-res):{nbadlowres}\"], color='C4',log=True)\n",
    "# add evt photon energy distribution to histogram\n",
    "hist(impact_energies,ax=ax2,alpha=0.1, bins='scott',label=[\"impact photons\"], color='C8',log=True)\n",
    "# plot a vertical line at 0.2 keV\n",
    "ax2.axvline(x=0.2, color='r', linestyle='--')\n",
    "\n",
    "ax2.legend(loc=\"upper right\", fontsize='small')\n",
    "ax2.set_xlabel(\"Energy (keV)\")\n",
    "ax2.set_ylabel(\"# photons\")\n",
    "ax2.set_title(\"Photon energy distribution\")\n",
    "plt.show()\n",
    "# save image to PDF file\n",
    "fig.savefig(f\"./Figures/missing_{filter}_{focus}_{flux_mcrab:.2f}mCrab.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSFCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
