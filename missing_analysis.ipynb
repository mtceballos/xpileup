{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of missing pulses   \n",
    "\n",
    "For a given flux and exposure time this notebook analyzes the missing ('non-reconstructed') photons and plots the\n",
    "distribution of separations to their partner ('Bad-reconstructed' pulse).\n",
    "\n",
    "1. Import modules   \n",
    "2. Read parameters of simulation   \n",
    "3. Analysis of bad/non-reconstructed pulses   \n",
    "   * 3.1. Check distances between a missing photon and its corresponding \"bad-reconstructed\" photon:    \n",
    "        - For each simulation:   \n",
    "            * read CSV file with assignation of *missing* & *bad-reconstructed*   \n",
    "            * for each *missing* photon: get *bad-reconstructed* partner   \n",
    "                * read info in `piximpact` file   \n",
    "                * calculate minimum of the distances to all *bad-reconstructed*: this is its partner   \n",
    "                * save distance to global list of distances    \n",
    "                * Alert if:   \n",
    "                    * No *bad-reconstructed* photon is found for each *missing* photon: raise Error    \n",
    "                    * Separation [*missing*-*bad_renconstructed*] > close_dist_xifusim: raise Error (it should never happen)    \n",
    "                    * Separation [*missing*-*bad_renconstructed*] > 30: warning to check particular cases    \n",
    "    * 3.2 Plot histograms of:   \n",
    "        - separations   \n",
    "        - energies:\n",
    "            - energies of missing photons   \n",
    "            - energies of badrecons photons   \n",
    "            - energies of impact photons   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(\"images/pileup.png\", width=350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "from astropy.io import fits, ascii\n",
    "from astropy.table import Table\n",
    "from astropy.visualization import hist\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import auxiliary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get parameters (check if running Jupyter notebook or Python script (Slurm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter handling\n",
    "def get_parameters():\n",
    "    \"\"\"\n",
    "    Get parameters for pairs detection analysis.\n",
    "    If running in a Jupyter Notebook, use default parameters.\n",
    "    If running as a script (e.g., SLURM), parse command line arguments.\n",
    "    \"\"\"\n",
    "    if auxiliary.is_notebook():\n",
    "        # Default parameters for interactive use\n",
    "        print(\"Running in notebook mode for source simulation\")\n",
    "        return {\n",
    "            \"config_version\": \"v5_20250621\",\n",
    "            \"global_csv_file\": \"info_nofilt_infoc_global_0.320mCrab.csv\",\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    else:\n",
    "        # Parse command line arguments for script execution\n",
    "        import argparse\n",
    "        parser = argparse.ArgumentParser(description=\"Parameters for pairs detection analysis\")\n",
    "        parser.add_argument(\"--config_version\", type=str, default=\"v5_20250621\", help=\"Configuration version\")\n",
    "        parser.add_argument(\"--global_csv_file\", type=str, default=\"info_nofilt_infoc_global_0.320mCrab.csv\", help=\"Global CSV file\")\n",
    "        parser.add_argument(\"--verbose\", type=int, default=1, help=\"Verbosity level\")\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "        return {\n",
    "            \"config_version\": args.config_version,\n",
    "            \"global_csv_file\": args.global_csv_file,\n",
    "            \"verbose\": args.verbose\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_parameters()\n",
    "config_version = params[\"config_version\"]\n",
    "global_csv_file = params[\"global_csv_file\"]\n",
    "verbose = params[\"verbose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(global_csv_file):\n",
    "    raise FileNotFoundError(f\"File {global_csv_file} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsims = 100\n",
    "sampling_rate=130210 #Hz\n",
    "secondary_samples = 1563\n",
    "if config_version == \"v3_20240917\":\n",
    "    close_dist_toxifusim = 100 #samples for close events to decide if xifusim simulation will be done\n",
    "elif config_version == \"v5_20250621\":\n",
    "    close_dist_toxifusim = 200 #samples for close events to decide if xifusim simulation will be done\n",
    "else:\n",
    "    raise ValueError(f\"Unknown config_version: {config_version}\")\n",
    "\n",
    "pileup_dist = 30\n",
    "auxiliary.verbose = verbose\n",
    "\n",
    "# get filter from file name\n",
    "filter = global_csv_file.split(\"_\")[1]\n",
    "# get focus from file name\n",
    "focus = global_csv_file.split(\"_\")[2]\n",
    "# get flux from file name\n",
    "flux_mcrab = float(global_csv_file.split(\"_\")[4].split(\"m\")[0])\n",
    "fluxDir = f\"{os.getcwd()}/{config_version}/flux{flux_mcrab:.2f}mcrab/\"\n",
    "print(f\"Filter: {filter}, Focus: {focus}, Flux: {flux_mcrab} mCrab\")\n",
    "if flux_mcrab > 999.:\n",
    "    nsims = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of missing and bad-reconstructed photons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pile-up photons separations \n",
    "\n",
    "Check distances between a missing photon and its corresponding \"bad-reconstructed\" photon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_missing_distances = list()\n",
    "all_missing_energies  = list()\n",
    "all_badrecons_energies = list()\n",
    "miss0_energies = list() # energies of the first missing photon\n",
    "all_badrecons_energies_secondaries = list()\n",
    "all_badrecons_energies_lowres = list()\n",
    "all_badrecons_energies_primaries = list()\n",
    "Ntimes_couples_far = 0\n",
    "\n",
    "for i in range(nsims):\n",
    "    isim = i + 1\n",
    "    #if not isim == 1:\n",
    "    #    continue\n",
    "    csv_file = f\"{fluxDir}/sim_{isim}/00_info_{filter}_{focus}_sim{isim}_missing.csv\"\n",
    "    # read table and ignore lines with \"#\"\n",
    "    missing_table = pd.read_csv(csv_file, comment=\"#\", converters={\"Bad-reconstructed photons\": ast.literal_eval,\n",
    "                                                    \"Bad-reconstructed photons energy\": ast.literal_eval,\n",
    "                                                    \"Non-reconstructed photons\": ast.literal_eval,\n",
    "                                                    \"Non-reconstructed photons energies\": ast.literal_eval,\n",
    "                                                    \"GRADE1 Bad-recons\": ast.literal_eval,\n",
    "                                                    \"GRADE2 Bad-recons\": ast.literal_eval})\n",
    "    \n",
    "    #read table row by row:\n",
    "    # 1st column: pixel id\n",
    "    # 2nd column: PH_ID of the badrecons photon\n",
    "    # 3rd column: energy of the badrecons photon\n",
    "    # 4th column: list of the PH_IDs of the missing photons for the badrecons photon\n",
    "    # 5th column: list of the energies of the missing photons for the badrecons photon\n",
    "    # 6th column: GRADE1 of the badrecons photon\n",
    "    # 7th column: GRADE2 of the badrecons photon\n",
    "\n",
    "    # read table rows grouped by pixel\n",
    "    pixels_in_table = missing_table[\"Pixel\"].unique()\n",
    "    for ipixel in pixels_in_table:\n",
    "        rows_with_same_pixel = missing_table[missing_table[\"Pixel\"] == ipixel]\n",
    "            \n",
    "        # identify piximpact file for pixel\n",
    "        piximpact_file = glob.glob(f\"{fluxDir}/sim_{isim}/crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp*_RA0.0_Dec0.0_{filter}_{focus}_pixel{ipixel}_piximpact.fits\")\n",
    "        if len(piximpact_file) == 0:\n",
    "            print(f\"sim {isim}, pixel {ipixel}: no piximpact file found\")\n",
    "            raise ValueError(\"No piximpact file found\")\n",
    "        if len(piximpact_file) > 1:\n",
    "            print(f\"sim {isim}, pixel {ipixel}: more than one piximpact file found\")\n",
    "            raise ValueError(\"More than one piximpact file found\")\n",
    "        piximpact_file = piximpact_file[0]\n",
    "        # read TIME and PH_ID columns of piximpact FITS file\n",
    "        with fits.open(piximpact_file) as hdul:\n",
    "            piximpact_data = hdul[1].data\n",
    "            time_piximpact = piximpact_data[\"TIME\"].copy()\n",
    "            ph_id = piximpact_data[\"PH_ID\"].copy()\n",
    "        \n",
    "        #for i, row in missing_table.iterrows():\n",
    "        for irow, row in rows_with_same_pixel.iterrows():\n",
    "            bad_recons_ph_id_irow = row[\"Bad-reconstructed photons\"]\n",
    "            bad_recons_energy_irow = row[\"Bad-reconstructed photons energy\"]\n",
    "            missing_phs_id_irow = row[\"Non-reconstructed photons\"]\n",
    "            missing_energies_irow = row[\"Non-reconstructed photons energies\"]\n",
    "            bad_recons_grade1_irow = row[\"GRADE1 Bad-recons\"]\n",
    "            bad_recons_grade2_irow = row[\"GRADE2 Bad-recons\"]\n",
    "            message = (f\"For sim {isim}, pixel {ipixel}: \\n\"\n",
    "                       f\"    bad-recons ph: {bad_recons_ph_id_irow}, energy: {bad_recons_energy_irow} \\n\"\n",
    "                       f\"    missing phs: {missing_phs_id_irow}, energies: {missing_energies_irow} \\n\"\n",
    "                       f\"    grade1 {bad_recons_grade1_irow}, grade2 {bad_recons_grade2_irow}\")\n",
    "            auxiliary.vprint(message)\n",
    "            if not isinstance(bad_recons_energy_irow, (int, float, np.float32, np.float64)):\n",
    "                message = (f\"{bad_recons_energy_irow} (type: {type(bad_recons_energy_irow)}) is not a number\")\n",
    "                raise ValueError(message)\n",
    "\n",
    "            # foreach missing photon, find the TIME distance to its 'partner'-bad-reconstructed photon\n",
    "            for imi in range(len(missing_phs_id_irow)):\n",
    "                imissing = missing_phs_id_irow[imi]\n",
    "                missing_energy = missing_energies_irow[imi]\n",
    "                missing_time = time_piximpact[ph_id == imissing][0] \n",
    "                bad_time = time_piximpact[ph_id == bad_recons_ph_id_irow][0]\n",
    "                time_diff_samples = np.abs(missing_time - bad_time)*sampling_rate\n",
    "                if time_diff_samples > close_dist_toxifusim:\n",
    "                    # this should never happen, as only couples separated by less than close_dist_toxifusim are simulated\n",
    "                    message = f\"sim {isim}, pixel {ipixel}: missing ph {imissing} and bad ph {bad_recons_ph_id_irow} are separated by {time_diff_samples:.2f} samples\"\n",
    "                    print(message)\n",
    "                    raise ValueError(message)\n",
    "                if time_diff_samples > pileup_dist:\n",
    "                    message = f\"Sim {isim}, pixel{ipixel}:Time difference between missing and bad reconstructed photons is too large:{time_diff_samples:.2f} samples\"\n",
    "                    print(message)\n",
    "                    Ntimes_couples_far += 1\n",
    "                # append the minimum time difference to the list of missing distances\n",
    "                all_missing_distances.append(time_diff_samples)\n",
    "                all_missing_energies.append(missing_energy)\n",
    "                auxiliary.vprint(f\"sim {isim}, pixel {ipixel}, missing ph {imissing}, bad ph {bad_recons_ph_id_irow}, min time diff {time_diff_samples:.2f}\")\n",
    "            imissing0 = missing_phs_id_irow[0]\n",
    "            \n",
    "            # check bad-recons photons\n",
    "            if bad_recons_grade2_irow <= secondary_samples:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {bad_recons_ph_id_irow}, grade1 {bad_recons_grade1_irow}, grade2 {bad_recons_grade2_irow}: SECONDARY\")\n",
    "                all_badrecons_energies_secondaries.append(bad_recons_energy_irow)\n",
    "            elif bad_recons_grade1_irow == 8:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {bad_recons_ph_id_irow}, grade1 {bad_recons_grade1_irow}, grade2 {bad_recons_grade2_irow}: LOWRES\")\n",
    "                all_badrecons_energies_lowres.append(bad_recons_energy_irow)\n",
    "            else:\n",
    "                auxiliary.vprint(f\"........bad-recons ph {bad_recons_ph_id_irow}, grade1 {bad_recons_grade1_irow}, grade2 {bad_recons_grade2_irow}: PRIMARY\")\n",
    "                all_badrecons_energies_primaries.append(bad_recons_energy_irow)\n",
    "            all_badrecons_energies.append(bad_recons_energy_irow)\n",
    "            # save energy of first missing photon for bad-recons photon\n",
    "            miss0_energies.append(missing_energies_irow[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Ntimes_couples_far > 0:\n",
    "    print(f\"Number of times couples far: {Ntimes_couples_far}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of pileup separations and energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read global CSV table with info of all simulations\n",
    "# look for \"Nimpacts\" column info selecting where the 'flux[mcrab]' matches the flux of the simulations\n",
    "global_table = pd.read_csv(global_csv_file)\n",
    "global_table = global_table[global_table[\"flux[mcrab]\"] == float(flux_mcrab)]\n",
    "global_table = global_table[global_table[\"filter\"] == filter]\n",
    "# get total number of impacts (for all 'simulation')\n",
    "print(\"Data from table:\")\n",
    "Nimpacts = global_table[\"Nimpacts\"].sum()\n",
    "print(f\"   Total number of impacts: {Nimpacts}\")\n",
    "Nmissing = len(all_missing_distances)\n",
    "print(f\"   Total number of missing impacts: {Nmissing}\")\n",
    "Nbadrecons = len(all_badrecons_energies)\n",
    "print(f\"   Total number of bad reconstructed impacts: {Nbadrecons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total distribution of photons from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ** ARF/RMF threshold = 0.15keV but X-IFU/XML readout threshold=0.2keV **\n",
    "# a) photons in impact list with 0.15keV<E<=0.2keV are not reconstructed by sixtesim (ENERGY assigned in EVT list is 0 keV)\n",
    "# b) if obtained from the impact list they will have the correct energy:\n",
    "#       -> simulated by xifusim but pulses will be probably undetectable (?)    \n",
    "# c) if not in the initial impact list (BGD photons):\n",
    "#       -> they are not simulated by xifusim and will have 0 energy  \n",
    "#       \n",
    "impact_energies = list()\n",
    "Nlow_total = 0\n",
    "Nevt_total = 0\n",
    "Nimp_total = 0\n",
    "evt_file = f\"crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp*_RA0.0_Dec0.0_{filter}_{focus}_evt.fits\"\n",
    "imp_file = f\"crab_flux{flux_mcrab:.2f}_Emin2_Emax10_exp*_RA0.0_Dec0.0_{filter}_{focus}_impact.fits\"\n",
    "\n",
    "for isim in range(1,nsims+1):\n",
    "    evt_file_sim = glob.glob(f\"{fluxDir}/sim_{isim}/{evt_file}\")\n",
    "    imp_file_sim = glob.glob(f\"{fluxDir}/sim_{isim}/{imp_file}\")\n",
    "    if len(evt_file_sim) == 0 or len(imp_file_sim) == 0:\n",
    "        raise ValueError(f\"evt or impact file not found for sim {isim}\")\n",
    "    if len(evt_file_sim) > 1 or len(imp_file_sim) > 1:\n",
    "        raise ValueError(f\"More than one evt or impact file found for sim {isim}\")\n",
    "    evt_file_sim = evt_file_sim[0]\n",
    "    imp_file_sim = imp_file_sim[0]\n",
    "        \n",
    "    print(f\"Saving energy of photons in impact list for sim {isim}...\")\n",
    "    # read PH_ID from evt_file and ENERGY from impact list\n",
    "    with fits.open(evt_file_sim) as hdul:\n",
    "        evt_data = hdul[1].data\n",
    "        evt_ph_id = evt_data[\"PH_ID\"].copy()\n",
    "        evt_energy = evt_data[\"SIGNAL\"].copy()\n",
    "    with fits.open(imp_file_sim) as hdul:\n",
    "        imp_data = hdul[1].data\n",
    "        imp_ph_id = imp_data[\"PH_ID\"].copy()\n",
    "        imp_energy = imp_data[\"ENERGY\"].copy()\n",
    "    # get the ENERGY of the photons in the impact list whose PH_ID is in the evt list\n",
    "    impact_energies_sim = imp_energy[np.isin(imp_ph_id, evt_ph_id)]\n",
    "    print(f\"           Number of photons in impact list: {len(imp_ph_id)}\")\n",
    "    print(f\"           Number of photons in evt list: {len(evt_ph_id)}\")\n",
    "    Nimp_total += len(imp_ph_id)\n",
    "    Nevt_total += len(evt_ph_id)\n",
    "    # add energies to the list\n",
    "    impact_energies.extend(impact_energies_sim)\n",
    "    # add the energies of the BGD photons in the evt list: PH_ID < 0\n",
    "    # they are not in the global impact list (but they are added to the pixel impact list and thus they are simulated)\n",
    "    bgd_ph_id = evt_ph_id[evt_ph_id < 0]\n",
    "    bgd_ph_energy = evt_energy[evt_ph_id < 0]\n",
    "    # add the energies to the list\n",
    "    impact_energies.extend(bgd_ph_energy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary\n",
    "Nlow_total = len([energy for energy in impact_energies if (energy < 0.2 and energy >0.)])\n",
    "Nbgd_total = len([energy for energy in impact_energies if (energy == 0)])\n",
    "print(f\"Total number of impacts (table): {Nimpacts}\")\n",
    "print(f\"Total number of impact energies: {len(impact_energies)}\")\n",
    "print(f\"Total number of event energies: {Nevt_total}\")\n",
    "print(f\"Total number of total impacts (pre-sixtesim): {Nimp_total}\")\n",
    "print(f\"Total number of missing impacts: {Nmissing}\")\n",
    "print(f\"Total number of bad reconstructed impacts: {Nbadrecons}\")\n",
    "nbadprim = len(all_badrecons_energies_primaries)\n",
    "nbadsec = len(all_badrecons_energies_secondaries)\n",
    "nbadlowres = len(all_badrecons_energies_lowres) \n",
    "print(f\"Number of bad reconstructed photons (primary): {nbadprim}\")\n",
    "print(f\"Number of bad reconstructed photons (secondary): {nbadsec}\")\n",
    "print(f\"Number of bad reconstructed photons (low-res): {nbadlowres}\")\n",
    "print(f\"Number of events with energy < 0.2 keV: {Nlow_total}\")\n",
    "print(f\"BGD events with 0 energy: {Nbgd_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of distribution of missing photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with two plots\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(12,6))\n",
    "# In ax1: plot histogram of distances (in samples) for missing photons\n",
    "# =====================================================================\n",
    "#ncts_bin, seps_bins, handle_seps = hist(all_missing_distances, bins='scott', ax=ax1, edgecolor='black')\n",
    "#print(f\"Bin size = {seps_bins[1]-seps_bins[0]:.2f} samples\")\n",
    "bin_size = 1 # samples\n",
    "seps_bins = np.arange(0, 110, bin_size)\n",
    "ncts_bin, seps_bins, handle_seps = hist(all_missing_distances, bins=seps_bins, ax=ax1, edgecolor='black')\n",
    "# set x axis limits\n",
    "ax1.set_xlim(0, 110)\n",
    "ax1.set_xlabel(\"Time difference (samples)\")\n",
    "ax1.set_ylabel(\"# missing photons\")\n",
    "ax1.set_title(\"Time separations of missing photons\")\n",
    "# write text on the plot: number of simulations, flux, exposure, sampling rate\n",
    "text = (f\"nsims = {nsims}\\n\"\n",
    "        f\"Nimpacts = {Nimpacts}\\n\"\n",
    "        f\"Nmissing = {Nmissing}\\n\"\n",
    "        f\"Nbadrecons = {Nbadrecons}\\n\"\n",
    "        f\"flux = {flux_mcrab} mCrab\\n\"\n",
    "        f\"Filter = {filter}\\n\"\n",
    "        f\"Focus = {focus}\\n\"\n",
    "        f\"N(E<0.2keV)={Nlow_total}\\n\"\n",
    "        f\"sampling rate = {sampling_rate} Hz\\n\"\n",
    "        f\"Ncouples(>{pileup_dist}sam) = {Ntimes_couples_far}\\n\") \n",
    "\n",
    "ax1.text(0.5, 0.95, text, transform=ax1.transAxes, fontsize=10, verticalalignment='top')\n",
    "\n",
    "# In ax2: plot histogram of energies of impact photons, missing photons and bad-reconstructed photons\n",
    "# ====================================================================================================\n",
    "#Ncts_bin, miss_bins, handle_miss = hist(all_missing_energies,ax=ax2, alpha=0.8, bins='scott',histtype='step',\n",
    "#                                        label=[\"missing photons\"], color='C0', log=True)\n",
    "#bin_size = miss_bins[1] - miss_bins[0]\n",
    "bin_size = 0.2 # keV\n",
    "miss_bins = np.arange(0, 12., bin_size)\n",
    "\n",
    "Ncts_bin, _, handle_miss = hist(all_missing_energies,ax=ax2, alpha=0.8, bins=miss_bins, histtype='step',\n",
    "                                        label=[\"missing photons\"], color='C0', log=True)\n",
    "\n",
    "_, _, handle_bad = hist(all_badrecons_energies,ax=ax2,alpha=0.8, bins=miss_bins, histtype='step',\n",
    "                        label=[\"bad-recons photons\\n(prim+second+low-res)\"], color='C1',log=True)\n",
    "\n",
    "if len(all_badrecons_energies_primaries) > 0:\n",
    "    _, _, handle_prim = hist(all_badrecons_energies_primaries,ax=ax2,alpha=0.5, bins=miss_bins,histtype='step',label=[f\"bad-recons photons\\n(primary):{nbadprim}\"],color='C2', log=True)\n",
    "if len(all_badrecons_energies_secondaries) > 0:\n",
    "    _, _, handle_sec = hist(all_badrecons_energies_secondaries,ax=ax2,alpha=0.5, bins=miss_bins,label=[f\"bad-recons photons\\n(secondary):{nbadsec}\"], color='C3',log=True)\n",
    "if len(all_badrecons_energies_lowres) > 0:\n",
    "    _, _, handle_low = hist(all_badrecons_energies_lowres,ax=ax2,alpha=0.5, bins=miss_bins,label=[f\"bad-recons photons\\n(low-res):{nbadlowres}\"], color='C4',log=True)\n",
    "# add evt photon energy distribution to histogram\n",
    "_, _, handle_all = hist(impact_energies,ax=ax2,alpha=0.3, bins=miss_bins,label=[\"impact photons\"], color='C8',log=True)\n",
    "# plot a vertical line at 0.2 keV\n",
    "handle_xifu = ax2.axvline(x=0.2, color='r', linestyle='--', alpha=0.5, label=\"X-IFU threshold\")\n",
    "\n",
    "# add re-scaled \"handle_all\" histogram to see if it keeps the same shape than the missing histogram\n",
    "all_np_hist, _ = np.histogram(impact_energies, bins=miss_bins)\n",
    "scaling_factor = Ncts_bin.sum() / all_np_hist.sum() # miss/all\n",
    "rescaled_all = all_np_hist * scaling_factor\n",
    "# Plot the rescaled histogram\n",
    "handle_re = ax2.step(miss_bins[:-1], rescaled_all, where='mid', linestyle=':', color='black', \n",
    "         label=\"impact photons (rescaled)\", alpha=0.8)\n",
    "\n",
    "# get the y-axis limits\n",
    "ymin, ymax = ax2.get_ylim()\n",
    "ymin = 0.9\n",
    "# set the y-axis limits\n",
    "ax2.set_ylim(ymin, ymax)\n",
    "# set x axis limits\n",
    "ax2.set_xlim(0, 12)\n",
    "\n",
    "# add legend in an specific order\n",
    "handles = [handle_all[0], handle_miss[0], handle_bad[0], handle_prim[0], handle_sec[0], handle_low[0], handle_re[0],handle_xifu]\n",
    "labels = [h.get_label() for h in handles]\n",
    "ax2.legend(handles, labels, loc='upper right', fontsize=8, frameon=False)\n",
    "\n",
    "ax2.set_xlabel(\"Energy (keV)\")\n",
    "ax2.set_ylabel(f\"# photons/{bin_size:.2f}keV\")\n",
    "ax2.set_title(\"Photon energy distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image to PDF file\n",
    "fig.savefig(f\"{config_version}/Figures/missing_histo/missing_{filter}_{focus}_{flux_mcrab:.2f}mCrab.pdf\", bbox_inches='tight')\n",
    "fig.savefig(f\"{config_version}/Figures/missing_histo/missing_{filter}_{focus}_{flux_mcrab:.2f}mCrab.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i, v in enumerate(all_badrecons_energies):\n",
    "    if not isinstance(v, (int, float, np.float32, np.float64)):\n",
    "        print(f\"Index {i}: {v} (type: {type(v)})\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image of combinations of energies of the bad-recons and their corresponding missing partner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2D map\n",
    "# X axis: energies of bad-reconstructed photons\n",
    "# Y axis: energies of missing photons (first of them if there are more than one for the same bad-reconstructed photon)\n",
    "# =====================================================================\n",
    "# create a 2D histogram\n",
    "histo_miss_bad = np.histogram2d(miss0_energies, all_badrecons_energies, bins=[np.linspace(0, 10, 100), np.linspace(0, 10, 100)])\n",
    "# create a figure\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(14, 6))\n",
    "# add title\n",
    "fig.suptitle(f\"Missing vs Bad-reconstructed photons: {flux_mcrab} mCrab, {filter}, {focus}\")\n",
    "# plot the histogram as an image\n",
    "im = ax1.imshow(histo_miss_bad[0], cmap='hot', interpolation='nearest', origin='lower', extent=[0, 10, 0, 10])\n",
    "# label x as \"Missing photon energy (keV)\"\n",
    "ax1.set_xlabel(\" (1st) Missing photon energy (keV)\")\n",
    "# label y as \"Bad-reconstructed photon energy (keV)\"\n",
    "ax1.set_ylabel(\"Bad-reconstructed photon energy (keV)\")\n",
    "# add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax1)\n",
    "cbar.set_label(\"# photons\")\n",
    "\n",
    "# plot the histogram as a contour plot\n",
    "contour = ax2.contour(histo_miss_bad[0], levels=10, cmap='hot', extent=[0, 10, 0, 10])\n",
    "# label x as \"Missing photon energy (keV)\"\n",
    "ax2.set_xlabel(\" (1st) Missing photon energy (keV)\")\n",
    "# label y as \"Bad-reconstructed photon energy (keV)\"\n",
    "ax2.set_ylabel(\"Bad-reconstructed photon energy (keV)\")\n",
    "# add colorbar\n",
    "cbar = plt.colorbar(contour, ax=ax2)\n",
    "cbar.set_label(\"# photons\")\n",
    "# save image to PDF file\n",
    "fig.savefig(f\"{config_version}/Figures/missing_images/missing_vs_badrecons_{filter}_{focus}_{flux_mcrab:.2f}mCrab.pdf\", bbox_inches='tight')\n",
    "fig.savefig(f\"{config_version}/Figures/missing_images/missing_vs_badrecons_{filter}_{focus}_{flux_mcrab:.2f}mCrab.png\", bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSFCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
