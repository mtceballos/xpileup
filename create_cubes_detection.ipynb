{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b70bfb3",
   "metadata": {},
   "source": [
    "# Analysis of detection algorithms for SIRENA\n",
    "\n",
    "Check results of possible input parameters\n",
    "\n",
    "* samplesUp (fixed): number of consecutive samples in the derivative above the threshold\n",
    "* samplesDown (fixed): number of consecutive samples in the derivative below the threshold to start triggering again\n",
    "* threshold (fixed): value to be crossed by the derivative\n",
    "\n",
    "* window: size (samples) of the window to calculate average derivative and do a subtraction   \n",
    "  Ex. window = 3  :  \n",
    "  ```\n",
    "  deriv[i] => deriv[i] - mean(deriv[i-1], deriv[i-2], deriv[i-3])\n",
    "  ```\n",
    "\n",
    "* offset: offset (samples) of the subtracting window   \n",
    "  Ex. window = 3 && offset = 2  :   \n",
    "  ```\n",
    "  deriv[i] => deriv[i] - mean(deriv[i-3], deriv[i-4], deriv[i-5])\n",
    "  ```\n",
    "\n",
    "## Procedure   \n",
    "1) (*external*) XIFUSIM files with 100 pairs of pulses are simulated:    \n",
    "```python\n",
    "    Eprimary = [0.2, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9 , 10, 11 ,12]    \n",
    "    Esecondary = [0.2, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9 , 10, 11 ,12]    \n",
    "    Separations = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,25,30,35,40,45,50,60,70,80,90,100,110,126]    \n",
    "```\n",
    "2) (*external*) SIRENA reconstructed (xifusim) files using combinations of window and offset:    \n",
    "```python\n",
    "    samplesUp = 3\n",
    "    samplesDown = 2   \n",
    "    threshold = 6\n",
    "    window = [0, 1, 2, 3, 4, 5, 6, 10, 15, 20]\n",
    "    offset = [0, 1, 2, 3, 4, 5, 6]\n",
    "    The combination window=0 & offset=0 corresponds to the traditional method (no derivative subtraction)   \n",
    "```\n",
    "3) (*external*) For each window/offset combination a pickle object (file) is created with the following information:   \n",
    "```python\n",
    "    | separation | energy1 | energy2 | window | offset | ndetected | nfake |\n",
    "    \n",
    "```\n",
    "4) Analysis in this notebook:    \n",
    "   \n",
    "   a) For each window/offset:\n",
    "    * Read pickle file   \n",
    "    * (Optionally) create a FITS data cube of number of detected photons: AXIS1-ENERGY1, AXIS2-ENERGY2, AXIS3-separations   \n",
    "    * Save number of photons lost: numpy[separations, window, offset]  (**Warning**: indexing in numpy and FITS is reversed)  \n",
    "    * Plot an image of E2 vs E1 for a given separation (data cube slice)   \n",
    "\n",
    "   b) Create a mosaic of images with all the windows and offsets    \n",
    "   c) Write a FITS cube with number of lost photons: AXIS1-window, AXIS2-offset, AXIS3-separations    \n",
    "   d) Collapse the cube in separations and take mean value: plot image of lost photons (offset vs window)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e4b07",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "> **NOTE**:   \n",
    "> to convert this notebook into a Python script (for Slurm), just \"*Export as*\" -> Python and comment the line: `%matplotlib widget`\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7528171",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e29022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python modules\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import for pickling\n",
    "import pickle\n",
    "from astropy import table\n",
    "from astropy.io import fits\n",
    "from auxiliary import create_fits_cube\n",
    "import matplotlib.colors as mcolors\n",
    "import ipywidgets as widgets\n",
    "%matplotlib widget\n",
    "#%matplotlib qt\n",
    "#%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eed8d28",
   "metadata": {},
   "source": [
    "## Running Jupyter or Python script?   \n",
    "* It tries to call get_ipython() (only available in IPython environments, like Jupyter).   \n",
    "* If the shell class name is \"ZMQInteractiveShell\", it confirms that you're in a Jupyter notebook (or JupyterLab).      \n",
    "* If it's a regular Python interpreter, the function returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect whether running in Jupyter Notebook or as a script\n",
    "def is_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        return shell == 'ZMQInteractiveShell'\n",
    "    except (NameError, ImportError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter handling\n",
    "def get_parameters():\n",
    "    \"\"\"\n",
    "    Get parameters for pairs detection analysis.\n",
    "    If running in a Jupyter Notebook, use default parameters.\n",
    "    If running as a script (e.g., SLURM), parse command line arguments.\n",
    "    \"\"\"\n",
    "    global th, sUp, sDown, windows, offsets, relevant_separations, xifu_config, create_cubes, sep_for_plot_mosaic\n",
    "\n",
    "    # Check if running in a Jupyter Notebook or as a script \n",
    "    if is_notebook():\n",
    "        # Default parameters for interactive use\n",
    "        print(\"Running in notebook mode for pairs detection analysis\")\n",
    "        return {\n",
    "            \"threshold\": 6.0, # threshold for detection\n",
    "            \"samplesUp\": 3,  # samples up for detection\n",
    "            \"samplesDown\": 2, # samples down for detection\n",
    "            \"windows\": [0,1, 2, 3, 4, 5, 6, 10, 15, 20], # subtraction derivative window for detection\n",
    "            \"offsets\": [0,1, 2, 3, 4, 5, 6],  # offset for subtraction window\n",
    "            \"relevant_separations\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,25,30,35,40,45,50,60,70,80,90,100,110,126], # relevant separations for the analysis\n",
    "            \"config_version\": 'v5_20250621',  # XIFU configuration\n",
    "            \"create_cubes\": False,  # flag to create cubes\n",
    "            \"sep_for_plot_mosaic\": 20, # samples separation for plotting the mosaic of slices of the data cube (if negative, no plotting)\n",
    "            \"windows_for_collapsed_cube\": [0,1,2,3,4,5,6] # window sizes for the collapsed cube\n",
    "        }\n",
    "    else:\n",
    "        # Parameters from command line (e.g., for SLURM)\n",
    "        parser = argparse.ArgumentParser(\n",
    "            description='Execute the python script for pairs detection analysis',\n",
    "            prog='execute_create_cubes.py')\n",
    "        parser.add_argument('--windows', required=False, type=int,\n",
    "                            nargs='*', default=[0, 1, 2, 3, 4, 5, 10, 15, 20],\n",
    "                            help='Subtraction derivative window for detection')\n",
    "        parser.add_argument('--offsets', required=False, type=int,\n",
    "                            nargs='*', default=[0, 1, 2, 3, 4, 5],\n",
    "                            help='Offset for subtraction window')           \n",
    "        parser.add_argument('--threshold', required=False, type=float, default=0.5,\n",
    "                            help='Threshold for detection')\n",
    "        parser.add_argument('--samplesUp', required=False, type=int, default=2,\n",
    "                            help='Samples up for detection')\n",
    "        parser.add_argument('--samplesDown', required=False, type=int, default=2,\n",
    "                            help='Samples down for detection')\n",
    "        parser.add_argument('--config_version', required=False, type=str, default='v5_20250621',\n",
    "                            help='XIFU configuration version')\n",
    "        parser.add_argument('--create_cubes', action='store_true',\n",
    "                            help='Flag to create cubes')\n",
    "        parser.add_argument('--relevant_separations', required=False, type=int,\n",
    "                            nargs='*', default=[8, 20, 50, 126, 317, 797],\n",
    "                            help='Relevant separations for the analysis')\n",
    "        parser.add_argument('--sep_for_plot_mosaic', required=False, type=int, default=-1,\n",
    "                            help='Samples separation for plotting the mosaic of slices of the data cube (if negative, no plotting)')\n",
    "        parser.add_argument('--win_collapsed_cube', required=False, type=int,\n",
    "                            nargs='*', default=[0, 1, 2, 3, 4, 5, 6],\n",
    "                            help='Window sizes for the collapsed cube')\n",
    "        \n",
    "        args = parser.parse_args()\n",
    "      \n",
    "        return vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a009c7",
   "metadata": {},
   "source": [
    "## Get parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_parameters()\n",
    "th = params['threshold']\n",
    "sUp = params['samplesUp']\n",
    "sDown = params['samplesDown']\n",
    "windows = params['windows']\n",
    "offsets = params['offsets']\n",
    "xifu_config = params['config_version']\n",
    "create_cubes = params['create_cubes']\n",
    "relevant_separations = params['relevant_separations']\n",
    "sep_for_plot_mosaic = params['sep_for_plot_mosaic']\n",
    "windows_for_collapsed_cube = params['win_collapsed_cube'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdff1c",
   "metadata": {},
   "source": [
    "### Secondary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_detected = 100\n",
    "max_detected = 200\n",
    "pickles_dir = \"/dataj6/ceballos/INSTRUMEN/EURECA/ERESOL/CEASaclay/July2025_v5_v20250621_offsetWindow/\"\n",
    "old_separations = [8, 20, 50, 126]  # default meaningful separations for window=0,10,15,20\n",
    "old_windows = [0, 10, 15, 20]  # old windows for the analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parameters\n",
    "print(f\"Parameters: th={th}, sUp={sUp}, sDown={sDown}, windows={windows}, offsets={offsets}, xifu_config={xifu_config}, create_cubes={create_cubes}, relevant_separations={relevant_separations}, sep_for_plot_mosaic={sep_for_plot_mosaic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a97563",
   "metadata": {},
   "source": [
    "## Create FITS cubes (for DS9) from pickle files   \n",
    "1. Data reconstruction results are saved in pickle files for each combination of window and offset    \n",
    "2. Create Data cubes:    \n",
    "\n",
    " | NAXIS3(sep)   \n",
    " |        \n",
    " |____ NAXIS1(e1)     \n",
    " /         \n",
    "NAXIS2(e2)\n",
    "\n",
    "3. Save nlost_pulses [separation, window, offset]    \n",
    "4. Plot E2 vs E1 mosaic of images   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41904a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_read = True  # flag to indicate if we are reading the first pickle file\n",
    "separations = None  # to store unique separations\n",
    "energies1 = None  # to store unique energies1\n",
    "energies2 = None  # to store unique energies2\n",
    "nrows = len(offsets)  # number of rows for the mosaic plot\n",
    "ncols = len(windows)  # number of columns for the mosaic plot\n",
    "\n",
    "# initialize a numpy array 3-D (sep, offset, window) for nlost_pulses with NaN values\n",
    "nlost_pulses = np.nan * np.ones((len(relevant_separations), len(offsets), len(windows_for_collapsed_cube)), dtype=float)\n",
    "#nlost_pulses = np.zeros((len(relevant_separations), len(offsets), len(windows_for_collapsed_cube)), dtype=int)\n",
    "\n",
    "if sep_for_plot_mosaic > 0:\n",
    "    sep = sep_for_plot_mosaic  # select the first separation for the mosaic\n",
    "    # create a mosaic figure (with squared plots) of the same slice in different data-cubes for each window and offset\n",
    "    fig_mosaic, ax_mosaic = plt.subplots(nrows, ncols, figsize=(18, 12), sharex=True, sharey=True)\n",
    "    fig_mosaic.suptitle(f'Mosaic of Detected Events Cube Slices by separation of the 2 pulses (config: {xifu_config=}, {th=}, {sUp=}, {sDown=}, {sep=})', fontsize=10)\n",
    "    \n",
    "for io in range(len(offsets)):\n",
    "    for iw in range(len(windows)):    \n",
    "        # get offset in inverse order for plotting reasons: mosaic plots would otherwise show the first offset at the top\n",
    "        io_plot = len(offsets) - 1 - io\n",
    "        off = offsets[io_plot]  # use the current offset for plotting\n",
    "        #off = offsets[io]  # use the current offset\n",
    "        win = windows[iw]\n",
    "        #print(f\"Offset: {off}, Window: {win}, io: {io}, iw: {iw}\")\n",
    "        #if win == 0: # for window=0 we use offset=0\n",
    "        #    off = 0\n",
    "        if win == 0 and off > 0:\n",
    "            # for window=0 we use offset=0\n",
    "            print(f\"    Skipping window {win} with offset {off} as it is not applicable.\")\n",
    "            continue\n",
    "        elif win in old_windows and off > 5:\n",
    "            #Skipping window {win} with offset {off} as it is not applicable.\n",
    "            print(f\"    Skipping window {win} with offset {off} as it is not applicable.\")\n",
    "            continue\n",
    "        pickle_file = f'{pickles_dir}/detectedFakes_win{win}_off{off}.pkl'\n",
    "        \n",
    "        # read the data from the pickle file\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            #print(data)\n",
    "            if win in old_windows:\n",
    "                use_separations = old_separations\n",
    "            else:\n",
    "                use_separations = relevant_separations\n",
    "            if win == 0 and off == 0:\n",
    "                  # for window=0 and offset=0 we use the default separations\n",
    "                data_table = table.Table(rows=data, names=('separation', 'energy1', 'energy2', 'samplesDown', 'samplesUp', 'threshold', 'ndetected', 'nfake'))\n",
    "                data_filtered = data_table[(data_table['threshold'] == th) & (data_table['samplesUp'] == sUp) & (data_table['samplesDown'] == sDown)]\n",
    "            else:\n",
    "                data_table = table.Table(rows=data, names=('separation', 'energy1', 'energy2', 'window', 'offset', 'ndetected', 'nfake')) \n",
    "                data_filtered = data_table.copy()\n",
    "        # get only separations that are in the relevant separations list\n",
    "        data_filtered = data_filtered[np.isin(data_filtered['separation'], use_separations)]\n",
    "        #print(f\"Filtered data: {data_filtered}\")\n",
    "        # print separations in data_filtered\n",
    "        #print(f\"Separations in data_filtered: {np.unique(data_filtered['separation'])}\")\n",
    "\n",
    "        if first_read:\n",
    "            separations = np.unique(data_filtered['separation'])\n",
    "            energies1 = np.unique(data_filtered['energy1'])\n",
    "            energies2 = np.unique(data_filtered['energy2'])\n",
    "            nsimulated = 200 * len(energies1) * len(energies2)  # total number of simulated events\n",
    "            e1_labs = [f'{e:.0f}' for e in energies1]\n",
    "            e1_labs[0] = f\"{energies1[0]:.1f}\"  # first label with one decimal\n",
    "            e1_labs[1] = f\"{energies1[1]:.1f}\"  # second label with one decimal\n",
    "            e2_labs = [f'{e:.0f}' for e in energies2]\n",
    "            e2_labs[0] = f\"{energies2[0]:.1f}\"  # first label with one decimal\n",
    "            e2_labs[1] = f\"{energies2[1]:.1f}\"  # second label with one decimal\n",
    "            first_read = False\n",
    "\n",
    "        #look for rows where nfake > 0\n",
    "        data_filtered_nfake = data_filtered[data_filtered['nfake'] > 0]\n",
    "        if len(data_filtered_nfake) > 0:\n",
    "            print(f\"Filtered data with nfake > 0: {data_filtered_nfake}\") \n",
    "\n",
    "        # create a data cube for each pickle file (and optionally save it to a FITS file)\n",
    "        data_cube_detections_iw_io_file=\"\"\n",
    "        if create_cubes:\n",
    "            data_cube_detections_iw_io_file = f\"analysis_pairs/detected_events_cube_win{win}_off{off}.fits\"\n",
    "        data_cube_detections_iw_io = create_fits_cube(data_filtered, data_cube_file=data_cube_detections_iw_io_file)\n",
    "        #print(f\"Data cube created with shape: {data_cube_detections_iw_io.shape} for window {win} and offset {off}\")\n",
    "        # store nlost pulses in the 3D array\n",
    "        for isep, sep in enumerate(use_separations):\n",
    "            data_slice_sep = data_cube_detections_iw_io[isep, :, :]\n",
    "            # calculate the number of detected events in the slice\n",
    "            ndetected_slice = np.sum(data_slice_sep)\n",
    "            nlost_slice = ndetected_slice - nsimulated\n",
    "            # use io reversed index for FITS cube so that the first offset is at the bottom of the plot\n",
    "            if win in windows_for_collapsed_cube: \n",
    "                nlost_pulses[isep, io_plot, iw] = nlost_slice\n",
    "                #print(f\"    Window: {win}, Offset: {off}, Separation: {sep}, N. lost: {nlost_slice}, N. detected: {ndetected_slice}\")\n",
    "                \n",
    "\n",
    "        if sep_for_plot_mosaic > 0:\n",
    "            # plot mosaic of slices of the data cube\n",
    "            # --------------------------------------\n",
    "            #print(f\"    Plotting mosaic for io {io} and iw {iw}\")\n",
    "            # create a normalization for the color map\n",
    "            norm = mcolors.Normalize(vmin=min_detected, vmax=max_detected)\n",
    "            cmap = plt.get_cmap('viridis')\n",
    "            # create a new figure for each window and offset using the slice for the separation_index\n",
    "            #separation_index = np.where(separations == sep_for_plot_mosaic)[0][0]\n",
    "            separation_index = np.where(np.array(use_separations) == sep_for_plot_mosaic)[0][0]\n",
    "            data_slice_sep = data_cube_detections_iw_io[separation_index, :, :]\n",
    "            # if the separation is not in the data cube, skip this plot\n",
    "            # calculate the number of detected events in the slice\n",
    "            ndetected_slice = np.sum(data_slice_sep)\n",
    "            nlost_slice = ndetected_slice - nsimulated\n",
    "            \n",
    "            im = ax_mosaic[io, iw].imshow(data_slice_sep, aspect='auto', origin='lower', cmap=cmap, norm=norm, interpolation='nearest')\n",
    "            ax_mosaic[io, iw].set_title(f'Window: {windows[iw]}, Offset: {off}\\n N. lost={nlost_slice}', fontsize=8)\n",
    "            ax_mosaic[io, iw].set_xlabel('Energy primary (keV)', fontsize=8)\n",
    "            ax_mosaic[io, iw].set_ylabel('Energy secondary (keV)', fontsize=8)\n",
    "            ax_mosaic[io, iw].set_xticks(np.arange(len(energies1)))\n",
    "            ax_mosaic[io, iw].set_xticklabels(e1_labs, rotation=45, fontsize=8)\n",
    "            ax_mosaic[io, iw].set_yticks(np.arange(len(energies2)))\n",
    "            ax_mosaic[io, iw].set_yticklabels(e2_labs, fontsize=8)    \n",
    "            ax_mosaic[io, iw].set_aspect('equal')\n",
    "            # add color bar to each subplot\n",
    "            cbar = fig_mosaic.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax_mosaic[io, iw], fraction=0.046, pad=0.04)\n",
    "            cbar.ax.tick_params(labelsize=8)  # adjust color bar tick label size    \n",
    "if sep_for_plot_mosaic > 0:\n",
    "    # adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # save the mosaic figure (png and PDF)\n",
    "    fig_mosaic.savefig(f'analysis_pairs/mosaic_detected_events_cube_slices_windows_offsets.png', dpi=300, bbox_inches='tight')\n",
    "    fig_mosaic.savefig(f'analysis_pairs/mosaic_detected_events_cube_slices_windows_offsets.pdf', bbox_inches='tight')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed22c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sep_for_plot_mosaic > 0:\n",
    "    # save the mosaic figure (png and PDF)\n",
    "    fig_mosaic.savefig(f'analysis_pairs/mosaic_detected_events_cube_slices_sep{sep_for_plot_mosaic}_windows_offsets.png', dpi=300, bbox_inches='tight')\n",
    "    fig_mosaic.savefig(f'analysis_pairs/mosaic_detected_events_cube_slices_sep{sep_for_plot_mosaic}_windows_offsets.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c91aa",
   "metadata": {},
   "source": [
    "## Create cube of nlost_pulses\n",
    "\n",
    " | NAXIS3(sep)   \n",
    " |        \n",
    " |____ NAXIS1(window)     \n",
    " /         \n",
    "NAXIS2(offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18671563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a FITS cube with the nlost_pulses[sep, offset, window]\n",
    "hdu = fits.PrimaryHDU(nlost_pulses)\n",
    "hdu.header['SEPS'] = ', '.join(map(str, relevant_separations)) # axis3\n",
    "hdu.header['OFFSETS'] = ', '.join(map(str, offsets)) #axis2\n",
    "hdu.header['WINDOWS'] = ', '.join(map(str, windows_for_collapsed_cube)) # axis1\n",
    "# set units for the axes: samples\n",
    "hdu.header['CUNIT3'] = 'samples'\n",
    "hdu.header['CUNIT2'] = 'samples'\n",
    "hdu.header['CUNIT1'] = 'samples'\n",
    "# save the FITS file\n",
    "hdu.writeto('analysis_pairs/nlost_pulses_cube.fits', overwrite=True)\n",
    "print(\"nlost_pulses cube saved to nlost_pulses_cube.fits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131c18c",
   "metadata": {},
   "source": [
    "## Collapse nlost_pulses cube\n",
    "\n",
    "1. Take mean value along separations axis   \n",
    "2. Plot collapsed image   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e426d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the nlost_pulses cube -> should be (separations, offsets, windows)\n",
    "print(f\"nlost_pulses shape: {nlost_pulses.shape}\")\n",
    "# collase cube in axis 0 (separation) to get the mean of lost photons and plot image (account for nans)\n",
    "nlost_pulses_collapsed = np.nanmean(nlost_pulses, axis=0)  # collapse the cube in axis 0 (separation)\n",
    "print(nlost_pulses_collapsed.shape)  # should be (offsets, windows)\n",
    "# create a new figure for the collapsed cube\n",
    "fig_collapsed, ax_collapsed = plt.subplots(figsize=(8, 6))\n",
    "# create a normalization for the color map\n",
    "norm_collapsed = mcolors.Normalize()\n",
    "cmap_collapsed = plt.get_cmap('viridis')\n",
    "# plot the collapsed cube\n",
    "im_collapsed = ax_collapsed.imshow(nlost_pulses_collapsed, origin='lower', aspect='auto', cmap=cmap_collapsed, norm=norm_collapsed, interpolation='nearest')\n",
    "ax_collapsed.set_title(f'Collapsed N. lost pulses (config: {xifu_config=}, {th=}, {sUp=}, {sDown=})', fontsize=10)\n",
    "ax_collapsed.set_ylabel('Offset (samples)')\n",
    "ax_collapsed.set_xlabel('Window (samples)')\n",
    "ax_collapsed.set_yticks(np.arange(len(offsets)))\n",
    "ax_collapsed.set_yticklabels(offsets, rotation=45, fontsize=8)\n",
    "ax_collapsed.set_xticks(np.arange(len(windows_for_collapsed_cube)))\n",
    "ax_collapsed.set_xticklabels(windows_for_collapsed_cube, fontsize=8)\n",
    "# add color bar to the collapsed plot\n",
    "cbar_collapsed = fig_collapsed.colorbar(plt.cm.ScalarMappable(norm=norm_collapsed, cmap=cmap_collapsed), ax=ax_collapsed, fraction=0.032, pad=0.04)\n",
    "cbar_collapsed.ax.tick_params(labelsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# save the collapsed figure (png and PDF)\n",
    "fig_collapsed.savefig(f'analysis_pairs/collapsed_nlost_pulses_cube_windows_offsets.png', dpi=300, bbox_inches='tight')\n",
    "fig_collapsed.savefig(f'analysis_pairs/collapsed_nlost_pulses_cube_windows_offsets.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b503b334",
   "metadata": {},
   "source": [
    "### Some DUMB tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "win= 4\n",
    "off = 0\n",
    "# print values of nlost_pulses for window=win, offset=off and separation=sep_for_plot_mosaic\n",
    "isep = np.where(np.array(relevant_separations) == sep_for_plot_mosaic)[0][0]  # find the index of separation=sep_for_plot_mosaic\n",
    "iw = windows_for_collapsed_cube.index(win)  # find the index of window=win\n",
    "io = np.where(np.array(offsets) == off)[0][0]  # find the index of offset=off  \n",
    "\n",
    "print(f\"nlost_pulses_collapsed[io, iw]: {nlost_pulses_collapsed[io, iw]}\")\n",
    "print(f\"nlost_pulses[isep, io, iw]: {nlost_pulses[isep, io, iw]}\")  # print the value for separation=20, window=6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "########### TESTING PART ###########\n",
    "# This part is for testing purposes only, to read the data from a pickle file and print\n",
    "# the filtered data and an example row with specific values.\n",
    "# It should not be part of the main code execution.\n",
    "\n",
    "#read the data for window=20 and offset=0\n",
    "win = 1\n",
    "off = 0\n",
    "e1 = 0.5\n",
    "e2 = 12\n",
    "pickle_file = f'detectedFakes_win{win}_off{off}.pkl'\n",
    "# read the data from the pickle file\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    data_table = table.Table(rows=data, names=('separation', 'energy1', 'energy2', 'window', 'offset', 'ndetected', 'nfake')) \n",
    "    data_filtered = data_table.copy()\n",
    "#print(f\"Filtered data: {data_filtered}\")\n",
    "# print row with seaparation=20, energy1=0.2, energy2=0.5\n",
    "example_row = data_filtered[(data_filtered['separation'] == sep_for_plot_mosaic) & (data_filtered['energy1'] == e1) & (data_filtered['energy2'] == e2)]\n",
    "#print(f\"Example row: {example_row}\")\n",
    "# print separations, energies1, energies2\n",
    "print(f\"Separation: {separations}, Energies1: {energies1}, Energies2: {energies2}\")\n",
    "# print the number of detected events in the example\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc951d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSFCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
